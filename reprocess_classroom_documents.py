"""
Google Classroom ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å†å‡¦ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

æ—¢å­˜ã® TwoStageIngestionPipeline ã‚’ä½¿ç”¨ã—ã¦ã€
Google Classroomã‹ã‚‰å–ã‚Šè¾¼ã¾ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å®Œå…¨ã«å†å‡¦ç†ã—ã¾ã™ã€‚

å‡¦ç†å†…å®¹:
1. workspace='ikuya_classroom' ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å–å¾—
2. original_file_id ã‚’ä½¿ã£ã¦Google Driveã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
3. æ—¢å­˜ã®2æ®µéšãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆGeminiåˆ†é¡ + ClaudeæŠ½å‡ºï¼‰ã§å‡¦ç†
4. full_textã€æ§‹é€ åŒ–metadataã€embedding ã‚’ç”Ÿæˆ
5. workspace ã‚’ IKUYA_SCHOOL ã«ä¿®æ­£
"""

import asyncio
from typing import List, Dict, Any
from loguru import logger
import json

from core.database.client import DatabaseClient
from pipelines.two_stage_ingestion import TwoStageIngestionPipeline
class ClassroomReprocessor:
    """Google Classroomãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å†å‡¦ç†"""

    def __init__(self):
        self.db = DatabaseClient()
        self.pipeline = TwoStageIngestionPipeline()

    def get_classroom_documents(self, limit: int = 100) -> List[Dict[str, Any]]:
        """
        å†å‡¦ç†å¯¾è±¡ã®Google Classroomãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å–å¾—

        Args:
            limit: å–å¾—ä»¶æ•°ã®ä¸Šé™

        Returns:
            ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒªã‚¹ãƒˆ
        """
        logger.info("Google Classroomãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å–å¾—ä¸­...")

        result = self.db.client.table('documents').select('*').eq(
            'workspace', 'ikuya_classroom'
        ).limit(limit).execute()

        documents = result.data if result.data else []
        logger.info(f"{len(documents)}ä»¶ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å–å¾—ã—ã¾ã—ãŸ")

        return documents

    def extract_file_id(self, doc: Dict[str, Any]) -> str:
        """
        ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰Google Drive ãƒ•ã‚¡ã‚¤ãƒ«IDã‚’æŠ½å‡º

        Args:
            doc: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¾æ›¸

        Returns:
            ãƒ•ã‚¡ã‚¤ãƒ«IDã€è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ç©ºæ–‡å­—åˆ—
        """
        # 1. drive_file_id ã‚’å„ªå…ˆ
        if doc.get('drive_file_id'):
            return doc['drive_file_id']

        # 2. metadata->original_file_id ã‚’ç¢ºèª
        metadata = doc.get('metadata', {})
        if isinstance(metadata, str):
            try:
                metadata = json.loads(metadata)
            except:
                metadata = {}

        if metadata.get('original_file_id'):
            return metadata['original_file_id']

        # 3. source_id ã‚’ç¢ºèªï¼ˆãŸã ã—ã“ã‚Œã¯ClassroomæŠ•ç¨¿IDã®å¯èƒ½æ€§ï¼‰
        # source_idãŒé•·ã„æ•°å­—ã®å ´åˆã¯Classroom IDãªã®ã§ä½¿ã‚ãªã„
        source_id = doc.get('source_id', '')
        if source_id and not source_id.isdigit():
            return source_id

        return ''

    async def reprocess_document(self, doc: Dict[str, Any], preserve_workspace: bool = True) -> bool:
        """
        å˜ä¸€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å†å‡¦ç†

        Args:
            doc: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¾æ›¸
            preserve_workspace: Trueã®å ´åˆã€æ—¢å­˜ã®workspaceã‚’ä¿æŒ

        Returns:
            æˆåŠŸã—ãŸã‹ã©ã†ã‹
        """
        doc_id = doc['id']
        file_name = doc['file_name']
        existing_workspace = doc.get('workspace', 'unknown')

        logger.info(f"\n{'='*80}")
        logger.info(f"å†å‡¦ç†é–‹å§‹: {file_name}")
        logger.info(f"Document ID: {doc_id}")
        logger.info(f"æ—¢å­˜ã®workspace: {existing_workspace}")

        # ãƒ•ã‚¡ã‚¤ãƒ«IDã‚’å–å¾—
        file_id = self.extract_file_id(doc)

        if not file_id:
            logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«IDãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_name}")
            logger.error(f"  drive_file_id: {doc.get('drive_file_id')}")
            logger.error(f"  source_id: {doc.get('source_id')}")
            logger.error(f"  metadata: {doc.get('metadata')}")
            return False

        logger.info(f"ä½¿ç”¨ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ID: {file_id}")

        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰ï¼ˆTwoStageIngestionPipeline.process_fileç”¨ï¼‰
        file_meta = {
            'id': file_id,
            'name': file_name,
            'mimeType': self._guess_mime_type(file_name)
        }

        # workspaceã‚’æ±ºå®š
        if preserve_workspace:
            workspace_to_use = existing_workspace
            logger.info(f"æ—¢å­˜ã®workspaceã‚’ä¿æŒ: {workspace_to_use}")
        else:
            workspace_to_use = "unknown"
            logger.info(f"workspaceã‚’Stage1ã«åˆ¤å®šã•ã›ã¾ã™")

        try:
            # æ—¢å­˜ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§å‡¦ç†
            result = await self.pipeline.process_file(
                file_meta=file_meta,
                workspace=workspace_to_use
            )

            if result and result.get('success'):
                logger.success(f"âœ… å†å‡¦ç†æˆåŠŸ: {file_name}")

                # å¤ã„ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’å‰Šé™¤ï¼ˆæ–°ã—ã„ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒä½œæˆã•ã‚Œã‚‹ãŸã‚ï¼‰
                logger.info(f"å¤ã„ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’å‰Šé™¤: {doc_id}")
                self.db.client.table('documents').delete().eq('id', doc_id).execute()

                return True
            else:
                logger.error(f"âŒ å†å‡¦ç†å¤±æ•—: {file_name}")
                return False

        except Exception as e:
            logger.error(f"âŒ å†å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {file_name}")
            logger.error(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {str(e)}")
            logger.exception(e)
            return False

    def _guess_mime_type(self, file_name: str) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ MIME ã‚¿ã‚¤ãƒ—ã‚’æ¨æ¸¬"""
        ext = file_name.lower().split('.')[-1] if '.' in file_name else ''

        mime_map = {
            'pdf': 'application/pdf',
            'jpg': 'image/jpeg',
            'jpeg': 'image/jpeg',
            'png': 'image/png',
            'gif': 'image/gif',
            'doc': 'application/msword',
            'docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
            'xls': 'application/vnd.ms-excel',
            'xlsx': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
        }

        return mime_map.get(ext, 'application/octet-stream')

    async def run(self, limit: int = 100, dry_run: bool = False, preserve_workspace: bool = True):
        """
        å†å‡¦ç†ã‚’å®Ÿè¡Œ

        Args:
            limit: å‡¦ç†ã™ã‚‹æœ€å¤§ä»¶æ•°
            dry_run: Trueã®å ´åˆã€å®Ÿéš›ã®å‡¦ç†ã¯è¡Œã‚ãšç¢ºèªã®ã¿
            preserve_workspace: Trueã®å ´åˆã€æ—¢å­˜ã®workspaceã‚’ä¿æŒ
        """
        logger.info("\n" + "="*80)
        logger.info("Google Classroom ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå†å‡¦ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
        logger.info("="*80)

        if dry_run:
            logger.warning("ğŸ” DRY RUN ãƒ¢ãƒ¼ãƒ‰: å®Ÿéš›ã®å‡¦ç†ã¯è¡Œã„ã¾ã›ã‚“")

        # å¯¾è±¡ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å–å¾—
        documents = self.get_classroom_documents(limit)

        if not documents:
            logger.info("å†å‡¦ç†å¯¾è±¡ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒã‚ã‚Šã¾ã›ã‚“")
            return

        logger.info(f"\nå‡¦ç†äºˆå®š: {len(documents)}ä»¶")
        if preserve_workspace:
            logger.info(f"Workspace: æ—¢å­˜ã®å€¤ã‚’ä¿æŒï¼ˆikuya_classroom ã®ã¾ã¾ï¼‰")
        else:
            logger.info(f"Workspace: Stage1 AIã«åˆ¤å®šã•ã›ã‚‹")

        # ç¢ºèª
        if not dry_run:
            print("\nå‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™ã‹ï¼Ÿ (y/N): ", end='')
            response = input().strip().lower()
            if response != 'y':
                logger.info("å‡¦ç†ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
                return

        # çµ±è¨ˆ
        success_count = 0
        failed_count = 0

        # å„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‡¦ç†
        for idx, doc in enumerate(documents, 1):
            logger.info(f"\n[{idx}/{len(documents)}] å‡¦ç†ä¸­...")

            if dry_run:
                file_id = self.extract_file_id(doc)
                logger.info(f"  ãƒ•ã‚¡ã‚¤ãƒ«: {doc['file_name']}")
                logger.info(f"  ãƒ•ã‚¡ã‚¤ãƒ«ID: {file_id or 'NOT FOUND'}")
                logger.info(f"  ç¾åœ¨ã®workspace: {doc.get('workspace')}")
                logger.info(f"  ç¾åœ¨ã®doc_type: {doc.get('doc_type')}")
                if preserve_workspace:
                    logger.info(f"  â†’ workspace: {doc.get('workspace')} (ä¿æŒ)")
                else:
                    logger.info(f"  â†’ workspace: Stage1ãŒåˆ¤å®š")
                continue

            # å®Ÿéš›ã®å†å‡¦ç†
            success = await self.reprocess_document(doc, preserve_workspace=preserve_workspace)

            if success:
                success_count += 1
            else:
                failed_count += 1

            # é€²æ—è¡¨ç¤º
            logger.info(f"é€²æ—: æˆåŠŸ={success_count}, å¤±æ•—={failed_count}")

        # æœ€çµ‚çµæœ
        logger.info("\n" + "="*80)
        logger.info("å†å‡¦ç†å®Œäº†")
        logger.info(f"æˆåŠŸ: {success_count}ä»¶")
        logger.info(f"å¤±æ•—: {failed_count}ä»¶")
        logger.info(f"åˆè¨ˆ: {len(documents)}ä»¶")
        logger.info("="*80)


async def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    import sys

    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®ãƒ‘ãƒ¼ã‚¹
    dry_run = '--dry-run' in sys.argv or '-n' in sys.argv
    preserve_workspace = '--preserve-workspace' not in sys.argv  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆTrue
    limit = 100

    # --limit ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®å‡¦ç†
    for arg in sys.argv:
        if arg.startswith('--limit='):
            try:
                limit = int(arg.split('=')[1])
            except:
                pass

    reprocessor = ClassroomReprocessor()
    await reprocessor.run(limit=limit, dry_run=dry_run, preserve_workspace=preserve_workspace)


if __name__ == "__main__":
    asyncio.run(main())
