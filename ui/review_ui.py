"""
Document Review UI (v2.0 - Tab Edition)
äººé–“ãŒAIã®æŠ½å‡ºçµæœã‚’ç¢ºèªãƒ»ä¿®æ­£ã™ã‚‹ãŸã‚ã®ç®¡ç†ç”»é¢

æ–°æ©Ÿèƒ½:
- ã‚¿ãƒ–ãƒ™ãƒ¼ã‚¹UI (ãƒ•ã‚©ãƒ¼ãƒ ç·¨é›† / è¡¨ã‚¨ãƒ‡ã‚£ã‚¿ / JSONãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼)
- ã‚¹ã‚­ãƒ¼ãƒãƒ™ãƒ¼ã‚¹ã®ãƒ•ã‚©ãƒ¼ãƒ ç·¨é›†
- ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«ã‚ˆã‚‹è¡¨å½¢å¼ç·¨é›†
- JSONå·®åˆ†è¡¨ç¤º
"""
import sys
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
root_dir = Path(__file__).parent.parent
sys.path.insert(0, str(root_dir))

import streamlit as st
import json
import tempfile
from typing import Dict, Any, Optional, List
import pandas as pd
from loguru import logger

from core.database.client import DatabaseClient
from core.connectors.google_drive import GoogleDriveConnector

# æ–°ã—ã„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from ui.utils.schema_detector import SchemaDetector
from ui.components.form_editor import render_form_editor
from ui.components.table_editor import render_table_editor, _render_array_table, _format_field_name
from ui.components.json_preview import render_json_preview, render_json_diff


def detect_structured_fields(metadata: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è‡ªå‹•æ¤œå‡º

    Args:
        metadata: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¾æ›¸

    Returns:
        æ§‹é€ åŒ–ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ãƒªã‚¹ãƒˆ [{"key": str, "label": str, "data": list}, ...]
    """
    structured_fields = []

    logger.info("=" * 60)
    logger.info("ğŸ” æ§‹é€ åŒ–ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ¤œå‡ºã‚’é–‹å§‹")
    logger.info(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ã‚­ãƒ¼æ•°: {len(metadata)}")
    logger.info("=" * 60)

    for key, value in metadata.items():
        # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°: å…¨ã¦ã®ã‚­ãƒ¼ã¨å€¤ã®å‹ã‚’å‡ºåŠ›
        logger.debug(f"Key: {key}, Type: {type(value)}, Value start: {str(value)[:50]}")

        # extracted_tablesã®ç‰¹åˆ¥å‡¦ç†
        if key == "extracted_tables":
            logger.info(f"ğŸ¯ FOUND extracted_tables! Type: {type(value)}, Length: {len(value) if isinstance(value, list) else 'N/A'}")
            if isinstance(value, list):
                logger.info(f"  First element type: {type(value[0]) if len(value) > 0 else 'empty'}")

        # text_blocksã¯ãƒ•ã‚©ãƒ¼ãƒ ç·¨é›†ã§è¡¨ç¤ºã™ã‚‹ãŸã‚ã€æ§‹é€ åŒ–ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¨ã—ã¦æ¤œå‡ºã—ãªã„
        if key == "text_blocks":
            logger.info(f"âš ï¸ '{key}' ã¯ãƒ•ã‚©ãƒ¼ãƒ ç·¨é›†ã§è¡¨ç¤ºã™ã‚‹ãŸã‚ã€æ§‹é€ åŒ–ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‹ã‚‰é™¤å¤–")
            continue

        # _list, _blocks, _matrix, _tables ã§çµ‚ã‚ã‚‹ã‚­ãƒ¼ã€ã¾ãŸã¯ structured_tables, weekly_schedule, extracted_tables ã‚’æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦èªè­˜
        if (key.endswith("_list") or key.endswith("_blocks") or
            key.endswith("_matrix") or key.endswith("_tables") or
            key == "structured_tables" or key == "weekly_schedule" or key == "extracted_tables"):
            logger.info(f"âœ“ '{key}' ã¯æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¨ã—ã¦æ¤œå‡º")

            if not isinstance(value, list):
                logger.warning(f"  âš ï¸ '{key}' ã¯ãƒªã‚¹ãƒˆã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚Type: {type(value)}")
                continue

            if len(value) == 0:
                logger.warning(f"  âš ï¸ '{key}' ã¯ç©ºã®ãƒªã‚¹ãƒˆã§ã™")
                continue

            logger.info(f"  âœ“ '{key}' ã¯ãƒªã‚¹ãƒˆã§ã€è¦ç´ æ•°: {len(value)}")

            # extracted_tablesã¯ç‰¹åˆ¥å‡¦ç†ï¼ˆæ–‡å­—åˆ—ã®ãƒªã‚¹ãƒˆã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›ï¼‰
            if key == "extracted_tables":
                logger.info(f"  âœ“ '{key}' ã¯ extracted_tables ã¨ã—ã¦æ¤œå‡º - ãƒ‘ãƒ¼ã‚¹å‡¦ç†ã‚’å®Ÿè¡Œ")
                from ui.utils.table_parser import parse_extracted_tables
                parsed_tables = parse_extracted_tables(value)
                if parsed_tables:
                    logger.info(f"  âœ“ {len(parsed_tables)} å€‹ã®è¡¨ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¾ã—ãŸ")
                    structured_fields.append({
                        "key": key,
                        "label": _format_field_name(key),
                        "data": parsed_tables
                    })
                else:
                    logger.warning(f"  âš ï¸ '{key}' ã®ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸ")
                continue

            # é…åˆ—ã®æœ€åˆã®è¦ç´ ãŒè¾æ›¸ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªï¼ˆæ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã®è¨¼æ‹ ï¼‰
            if isinstance(value[0], dict):
                logger.info(f"  âœ“ '{key}' ã®æœ€åˆã®è¦ç´ ã¯è¾æ›¸ã§ã™ â†’ æ§‹é€ åŒ–ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¨ã—ã¦æ¤œå‡º!")
                structured_fields.append({
                    "key": key,
                    "label": _format_field_name(key),
                    "data": value
                })
            else:
                logger.warning(f"  âš ï¸ '{key}' ã®æœ€åˆã®è¦ç´ ã¯è¾æ›¸ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚Type: {type(value[0])}")

    logger.info("=" * 60)
    logger.info(f"ğŸ¯ æ¤œå‡ºã•ã‚ŒãŸæ§‹é€ åŒ–ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ•°: {len(structured_fields)}")
    for field in structured_fields:
        logger.info(f"  - {field['key']} ({field['label']}) - {len(field['data'])} ä»¶")
    logger.info("=" * 60)

    return structured_fields


def download_file_from_drive(source_id: str, file_name: str) -> Optional[str]:
    """
    Google Driveã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

    Args:
        source_id: Google Driveã®ãƒ•ã‚¡ã‚¤ãƒ«ID
        file_name: ãƒ•ã‚¡ã‚¤ãƒ«å

    Returns:
        ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã€å¤±æ•—æ™‚ã¯None
    """
    try:
        drive_connector = GoogleDriveConnector()
        temp_dir = tempfile.gettempdir()
        file_path = drive_connector.download_file(source_id, file_name, temp_dir)
        return file_path
    except Exception as e:
        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return None


def pdf_review_ui():
    """PDFãƒ¬ãƒ“ãƒ¥ãƒ¼UIãƒ­ã‚¸ãƒƒã‚¯"""
    st.markdown("#### ğŸ“‹ PDFãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ¬ãƒ“ãƒ¥ãƒ¼")
    st.caption("AIãŒæŠ½å‡ºã—ãŸãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªãƒ»ä¿®æ­£ã§ãã¾ã™")

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¨ã‚¹ã‚­ãƒ¼ãƒæ¤œå‡ºå™¨ã®åˆæœŸåŒ–
    try:
        db_client = DatabaseClient()
        schema_detector = SchemaDetector()
    except Exception as e:
        st.error(f"åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        st.stop()

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼: æ¤œç´¢ã¨ãƒ•ã‚£ãƒ«ã‚¿è¨­å®š
    st.sidebar.header("ğŸ” æ¤œç´¢ & ãƒ•ã‚£ãƒ«ã‚¿")

    # Workspaceãƒ•ã‚£ãƒ«ã‚¿
    workspace_filter = st.sidebar.selectbox(
        "Workspace",
        options=["å…¨ã¦", "business", "personal"],
        index=0,
        help="ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°"
    )

    # æ¤œç´¢ãƒœãƒƒã‚¯ã‚¹
    search_query = st.sidebar.text_input(
        "IDã‚„ãƒ•ã‚¡ã‚¤ãƒ«åã§æ¤œç´¢",
        placeholder="ä¾‹: å­¦å¹´é€šä¿¡, abc123...",
        help="æ¤œç´¢ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã™ã‚‹ã¨ã€ãƒ¬ãƒ“ãƒ¥ãƒ¼çŠ¶æ…‹ã«é–¢ä¿‚ãªãå…¨ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ¤œç´¢ã—ã¾ã™"
    )

    # å–å¾—ä»¶æ•°
    limit = st.sidebar.number_input(
        "å–å¾—ä»¶æ•°",
        min_value=10,
        max_value=500,
        value=50,
        step=10,
        help="è¡¨ç¤ºã™ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æœ€å¤§ä»¶æ•°"
    )

    # ãƒ¢ãƒ¼ãƒ‰è¡¨ç¤º
    if search_query:
        st.sidebar.info("ğŸ” **æ¤œç´¢ãƒ¢ãƒ¼ãƒ‰**: å…¨ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ¤œç´¢ä¸­")
    else:
        st.sidebar.success("ğŸ“ **é€šå¸¸ãƒ¢ãƒ¼ãƒ‰**: æœªãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ã¿è¡¨ç¤º")

    # é€²æ—è¡¨ç¤º
    st.sidebar.markdown("---")
    st.sidebar.header("ğŸ“Š ãƒ¬ãƒ“ãƒ¥ãƒ¼é€²æ—")
    progress_data = db_client.get_review_progress()

    col_p1, col_p2 = st.sidebar.columns(2)
    with col_p1:
        st.metric("æœªãƒ¬ãƒ“ãƒ¥ãƒ¼", f"{progress_data['unreviewed']} ä»¶")
    with col_p2:
        st.metric("å®Œäº†", f"{progress_data['reviewed']} ä»¶")

    st.sidebar.progress(progress_data['progress_percent'] / 100)
    st.sidebar.caption(f"é€²æ—ç‡: {progress_data['progress_percent']}%")

    # ãƒªã‚¹ãƒˆæ›´æ–°ãƒœã‚¿ãƒ³
    st.sidebar.markdown("---")
    if st.sidebar.button("ğŸ”„ ãƒªã‚¹ãƒˆã‚’æ›´æ–°", use_container_width=True, key="refresh_pdf_list"):
        st.rerun()

    # ãƒ¬ãƒ“ãƒ¥ãƒ¼å¯¾è±¡ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å–å¾—
    with st.spinner("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å–å¾—ä¸­..."):
        # Workspaceãƒ•ã‚£ãƒ«ã‚¿ã®å€¤ã‚’å¤‰æ›ï¼ˆ"å…¨ã¦"ã®å ´åˆã¯Noneï¼‰
        workspace_value = workspace_filter if workspace_filter != "å…¨ã¦" else None

        documents = db_client.get_documents_for_review(
            limit=limit,
            search_query=search_query if search_query else None,
            workspace=workspace_value
        )

    # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°: å–å¾—å¾Œã®ç¢ºèª
    logger.info(f"DBã‹ã‚‰å–å¾—ã—ãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {len(documents)}ä»¶")

    if not documents:
        st.info("ãƒ¬ãƒ“ãƒ¥ãƒ¼å¯¾è±¡ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒã‚ã‚Šã¾ã›ã‚“")
        return

    st.sidebar.success(f"âœ… {len(documents)}ä»¶ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ")

    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒªã‚¹ãƒˆã‚’DataFrameã§è¡¨ç¤ºï¼ˆãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ä»˜ãï¼‰
    df_data = []
    for idx, doc in enumerate(documents):
        df_data.append({
            'é¸æŠ': False,  # ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ç”¨
            'ID': doc.get('id', '')[:8],
            'ãƒ•ã‚¡ã‚¤ãƒ«å': doc.get('file_name', ''),
            'æ–‡æ›¸ã‚¿ã‚¤ãƒ—': doc.get('doc_type', ''),
            'ä¿¡é ¼åº¦': round(doc.get('confidence') or 0, 3),
            'ä½œæˆæ—¥æ™‚': doc.get('created_at', '')[:10]
        })

    df = pd.DataFrame(df_data)

    # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°: DataFrameä½œæˆå¾Œã®ç¢ºèª
    logger.info(f"è¡¨ç¤ºç”¨DataFrameã®è¡Œæ•°: {len(df)}ä»¶")

    st.subheader("ğŸ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼å¯¾è±¡ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¸€è¦§")

    # ã¾ã¨ã‚ã¦å‰Šé™¤æ©Ÿèƒ½
    col_list_header, col_bulk_delete = st.columns([3, 1])
    with col_list_header:
        st.markdown("ä¸€è¦§ã‹ã‚‰é¸æŠã—ã¦ã¾ã¨ã‚ã¦å‰Šé™¤ã§ãã¾ã™")
    with col_bulk_delete:
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã§ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã®çŠ¶æ…‹ã‚’ç®¡ç†
        if 'selected_docs' not in st.session_state:
            st.session_state.selected_docs = []

    # ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ‡ã‚£ã‚¿ã§ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ä»˜ãã®è¡¨ã‚’è¡¨ç¤º
    edited_df = st.data_editor(
        df,
        use_container_width=True,
        height=200,
        hide_index=True,
        column_config={
            "é¸æŠ": st.column_config.CheckboxColumn(
                "é¸æŠ",
                help="å‰Šé™¤ã™ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’é¸æŠ",
                default=False,
            )
        },
        disabled=["ID", "ãƒ•ã‚¡ã‚¤ãƒ«å", "æ–‡æ›¸ã‚¿ã‚¤ãƒ—", "ä¿¡é ¼åº¦", "ä½œæˆæ—¥æ™‚"],
        key="document_list_editor"
    )

    # é¸æŠã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å–å¾—
    selected_indices = edited_df[edited_df['é¸æŠ'] == True].index.tolist()
    selected_count = len(selected_indices)

    # ã¾ã¨ã‚ã¦å‰Šé™¤ãƒœã‚¿ãƒ³
    if selected_count > 0:
        col_bulk1, col_bulk2, col_spacer = st.columns([1, 1, 2])

        with col_bulk1:
            st.warning(f"âš ï¸ {selected_count}ä»¶ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒé¸æŠã•ã‚Œã¦ã„ã¾ã™")

        with col_bulk2:
            # ä¸€æ‹¬å‰Šé™¤ç¢ºèªç”¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹
            if 'bulk_delete_confirm' not in st.session_state:
                st.session_state.bulk_delete_confirm = False

            if not st.session_state.bulk_delete_confirm:
                if st.button(f"ğŸ—‘ï¸ {selected_count}ä»¶ã‚’ã¾ã¨ã‚ã¦å‰Šé™¤", use_container_width=True, type="secondary"):
                    st.session_state.bulk_delete_confirm = True
                    st.rerun()
            else:
                if st.button(f"âœ… {selected_count}ä»¶ã®å‰Šé™¤ã‚’å®Ÿè¡Œ", use_container_width=True, type="primary"):
                    with st.spinner(f"{selected_count}ä»¶ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‰Šé™¤ä¸­..."):
                        success_count = 0
                        fail_count = 0

                        for idx in selected_indices:
                            doc = documents[idx]
                            doc_id = doc.get('id')
                            file_id = doc.get('drive_file_id') or doc.get('source_id')

                            # Google Driveã‹ã‚‰å‰Šé™¤
                            if file_id:
                                try:
                                    drive_connector = GoogleDriveConnector()
                                    drive_connector.trash_file(file_id)
                                except Exception as e:
                                    logger.error(f"Google Driveå‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")

                            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å‰Šé™¤
                            if db_client.delete_document(doc_id):
                                success_count += 1
                            else:
                                fail_count += 1

                        if success_count > 0:
                            st.success(f"âœ… {success_count}ä»¶ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
                        if fail_count > 0:
                            st.error(f"âŒ {fail_count}ä»¶ã®å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ")

                        st.session_state.bulk_delete_confirm = False
                        st.balloons()
                        import time
                        time.sleep(1)
                        st.rerun()

                if st.button("âŒ ã‚­ãƒ£ãƒ³ã‚»ãƒ«", use_container_width=True):
                    st.session_state.bulk_delete_confirm = False
                    st.rerun()

    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆé¸æŠ
    st.subheader("ğŸ” ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè©³ç´°")

    # ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ã®ã‚­ãƒ¼ã«æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’å«ã‚ã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ¼ãƒ‰å¤‰æ›´æ™‚ã«ãƒªã‚»ãƒƒãƒˆ
    selector_key = f"document_selector_{search_query or 'normal'}"

    selected_index = st.selectbox(
        "ç·¨é›†ã™ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’é¸æŠ",
        range(len(documents)),
        format_func=lambda i: f"{documents[i].get('file_name', 'Unknown')} (ä¿¡é ¼åº¦: {documents[i].get('confidence') or 0:.3f})",
        key=selector_key
    )

    selected_doc = documents[selected_index]
    doc_id = selected_doc.get('id')

    # ãƒ‡ãƒãƒƒã‚°: é¸æŠã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ç¢ºèª
    logger.info(f"=== é¸æŠã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ ===")
    logger.info(f"selected_index: {selected_index}")
    logger.info(f"doc_id: {doc_id}")
    logger.info(f"file_name: {selected_doc.get('file_name')}")

    # å…ˆã«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæƒ…å ±ã‚’å–å¾—ï¼ˆst.rerun()ã®å‰ã«ï¼‰
    drive_file_id = selected_doc.get('drive_file_id')
    source_id = selected_doc.get('source_id')
    file_id = drive_file_id or source_id
    file_name = selected_doc.get('file_name', 'unknown')
    doc_type = selected_doc.get('doc_type', '')

    # metadataã‚’ãƒ‘ãƒ¼ã‚¹ï¼ˆJSONæ–‡å­—åˆ—ã®å ´åˆã¨è¾æ›¸ã®å ´åˆã®ä¸¡æ–¹ã«å¯¾å¿œï¼‰
    metadata = selected_doc.get('metadata') or {}
    if isinstance(metadata, str):
        try:
            metadata = json.loads(metadata)
        except json.JSONDecodeError:
            logger.error(f"Failed to parse metadata JSON for doc_id: {doc_id}")
            metadata = {}

    # extracted_tables ã‚«ãƒ©ãƒ ã®å†…å®¹ã‚’ metadata ã«çµ±åˆ
    if 'extracted_tables' in selected_doc and selected_doc['extracted_tables']:
        extracted_tables = selected_doc['extracted_tables']
        if isinstance(extracted_tables, str):
            try:
                extracted_tables = json.loads(extracted_tables)
            except json.JSONDecodeError:
                logger.error(f"Failed to parse extracted_tables JSON for doc_id: {doc_id}")
                extracted_tables = None
        if extracted_tables:
            metadata['extracted_tables'] = extracted_tables
            logger.info(f"Added extracted_tables to metadata: {len(extracted_tables)} tables")

    confidence = selected_doc.get('confidence') or 0

    # ãƒ‡ãƒãƒƒã‚°: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®çŠ¶æ…‹ã‚’ç¢ºèª
    logger.info(f"metadata keys: {list(metadata.keys())}")
    logger.info(f"metadata size: {len(str(metadata))} bytes")
    if 'extracted_tables' in metadata:
        logger.info(f"extracted_tables found in metadata: {len(metadata['extracted_tables'])} tables")

    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå¤‰æ›´ã‚’æ¤œå‡ºã—ã¦ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
    if 'previous_doc_id' not in st.session_state:
        st.session_state.previous_doc_id = doc_id

    if st.session_state.previous_doc_id != doc_id:
        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã€å…¨ã¦ã®ç·¨é›†é–¢é€£ã®ã‚­ãƒ¼ã‚’ã‚¯ãƒªã‚¢
        logger.info(f"ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå¤‰æ›´ã‚’æ¤œå‡º: {st.session_state.previous_doc_id} -> {doc_id}")
        logger.info(f"æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«å: {file_name}")

        # ç·¨é›†é–¢é€£ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ã‚¯ãƒªã‚¢
        # å¤ã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ã‚­ãƒ¼ã‚’å‰Šé™¤
        old_doc_id = st.session_state.previous_doc_id
        keys_to_remove = [
            key for key in st.session_state.keys()
            if (key.startswith('form_') or
                key.startswith(f'json_editor_{old_doc_id}') or
                key.startswith(f'text_editor_{old_doc_id}') or
                key.startswith('table_editor_'))
        ]

        for key in keys_to_remove:
            del st.session_state[key]
            logger.debug(f"  å‰Šé™¤: {key}")

        st.session_state.previous_doc_id = doc_id
        logger.info(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ã‚¯ãƒªã‚¢: {len(keys_to_remove)} keys removed")

        # ãƒšãƒ¼ã‚¸ã‚’å†ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°
        st.rerun()

    # åŸºæœ¬æƒ…å ±è¡¨ç¤º
    col1, col2, col3 = st.columns([2, 1, 1])
    with col1:
        st.markdown(f"**ãƒ•ã‚¡ã‚¤ãƒ«å**: {file_name}")
    with col2:
        st.markdown(f"**æ–‡æ›¸ã‚¿ã‚¤ãƒ—**: {doc_type}")
    with col3:
        st.markdown(f"**ä¿¡é ¼åº¦**: {confidence:.3f}")

    st.markdown("---")

    # ä¿®æ­£å±¥æ­´ã¨ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ï¼ˆPhase 2ï¼‰
    latest_correction_id = selected_doc.get('latest_correction_id')
    if latest_correction_id:
        with st.expander("ğŸ“œ ä¿®æ­£å±¥æ­´ã¨ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯", expanded=False):
            correction_history = db_client.get_correction_history(doc_id, limit=5)

            if correction_history:
                st.markdown(f"**ä¿®æ­£å›æ•°**: {len(correction_history)}å›")

                # æœ€æ–°ã®ä¿®æ­£æƒ…å ±
                latest_correction = correction_history[0]
                st.markdown(f"**æœ€æ–°ã®ä¿®æ­£æ—¥æ™‚**: {latest_correction.get('corrected_at')}")
                if latest_correction.get('corrector_email'):
                    st.markdown(f"**ä¿®æ­£è€…**: {latest_correction.get('corrector_email')}")

                # ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒœã‚¿ãƒ³
                col_rollback, col_spacer = st.columns([1, 2])
                with col_rollback:
                    if st.button("â®ï¸ ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆå…ƒã«æˆ»ã™ï¼‰", use_container_width=True, type="secondary"):
                        with st.spinner("ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ä¸­..."):
                            rollback_success = db_client.rollback_document(doc_id)

                        if rollback_success:
                            st.success("âœ… ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ã«æˆåŠŸã—ã¾ã—ãŸï¼å‰ã®çŠ¶æ…‹ã«æˆ»ã‚Šã¾ã—ãŸã€‚")
                            st.rerun()
                        else:
                            st.error("âŒ ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ã«å¤±æ•—ã—ã¾ã—ãŸ")

                # ä¿®æ­£å±¥æ­´ã®è©³ç´°è¡¨ç¤º
                with st.expander("ä¿®æ­£å±¥æ­´ã®è©³ç´°ã‚’è¡¨ç¤º", expanded=False):
                    for idx, correction in enumerate(correction_history):
                        st.markdown(f"### ä¿®æ­£ #{idx + 1}")
                        st.markdown(f"**æ—¥æ™‚**: {correction.get('corrected_at')}")
                        if correction.get('notes'):
                            st.markdown(f"**ãƒ¡ãƒ¢**: {correction.get('notes')}")

                        # ä¿®æ­£å‰å¾Œã®å·®åˆ†ã‚’è¡¨ç¤º
                        col_before, col_after = st.columns(2)
                        with col_before:
                            st.markdown("**ä¿®æ­£å‰**")
                            st.json(correction.get('old_metadata', {}), expanded=False)
                        with col_after:
                            st.markdown("**ä¿®æ­£å¾Œ**")
                            st.json(correction.get('new_metadata', {}), expanded=False)

                        st.markdown("---")
            else:
                st.info("ä¿®æ­£å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“")

    st.markdown("---")

    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ: å·¦ã«PDFãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€å³ã«ç·¨é›†ã‚¿ãƒ–
    col_left, col_right = st.columns([1, 1.2])

    with col_left:
        st.markdown("### ğŸ“„ PDFãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")

        # PDFã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¨è¡¨ç¤º
        if file_id and file_name.lower().endswith('.pdf'):
            with st.spinner("PDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­..."):
                file_path = download_file_from_drive(file_id, file_name)

            if file_path and Path(file_path).exists():
                # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°: PDFãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼å‰ã®ç¢ºèª
                import os
                logger.info(f"PDFãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼é–‹å§‹ã€‚ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹: {file_path}")
                logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {os.path.getsize(file_path)} bytes")

                # PDFãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤ºï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ç›´æ¥æ¸¡ã™ï¼‰
                try:
                    from streamlit_pdf_viewer import pdf_viewer
                    logger.info("streamlit_pdf_viewer ã‚’ä½¿ç”¨ã—ã¦PDFè¡¨ç¤ºï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ç›´æ¥æ¸¡ã—ï¼‰")
                    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ç›´æ¥æ¸¡ã™ã“ã¨ã§ã€å·¨å¤§ãªBase64æ–‡å­—åˆ—ã®ç”Ÿæˆã‚’å›é¿
                    pdf_viewer(file_path, height=700)
                except ImportError:
                    logger.warning("streamlit_pdf_viewer ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤ºã—ã¾ã™")
                    st.warning("PDFãƒ“ãƒ¥ãƒ¼ã‚¢ãƒ¼ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
                    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ç”¨ã«ãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
                    with open(file_path, 'rb') as f:
                        pdf_bytes = f.read()
                    st.download_button(
                        label="ğŸ“¥ PDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=pdf_bytes,
                        file_name=file_name,
                        mime="application/pdf",
                        use_container_width=True
                    )
                except Exception as e:
                    logger.error(f"PDFãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
                    st.warning(f"PDFãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")
                    # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ç”¨ã«ãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
                    try:
                        with open(file_path, 'rb') as f:
                            pdf_bytes = f.read()
                        st.download_button(
                            label="ğŸ“¥ PDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=pdf_bytes,
                            file_name=file_name,
                            mime="application/pdf",
                            use_container_width=True
                        )
                    except Exception as read_error:
                        logger.error(f"PDFãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {read_error}", exc_info=True)
                        st.error("PDFãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
            else:
                logger.warning(f"PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚file_path={file_path}, exists={Path(file_path).exists() if file_path else False}")
                st.warning("PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ")
        else:
            st.info("PDFãƒ•ã‚¡ã‚¤ãƒ«ä»¥å¤–ã¯ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã§ãã¾ã›ã‚“")

    with col_right:
        st.markdown("### âœï¸ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç·¨é›†")

        # ã‚¹ã‚­ãƒ¼ãƒã‚’æ¤œå‡º
        detected_schema = schema_detector.detect_schema(doc_type, metadata)

        if detected_schema:
            st.info(f"ğŸ¯ æ¤œå‡ºã•ã‚ŒãŸã‚¹ã‚­ãƒ¼ãƒ: **{detected_schema}**")
            editable_fields = schema_detector.get_editable_fields(detected_schema)
        else:
            st.warning("âš ï¸ ã‚¹ã‚­ãƒ¼ãƒãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚JSONç·¨é›†ãƒ¢ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚")
            editable_fields = []

        # ã€å‹•çš„ã‚¿ãƒ–ç”Ÿæˆã€‘æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è‡ªå‹•æ¤œå‡º
        structured_fields = detect_structured_fields(metadata)

        # æ§‹é€ åŒ–ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ã‚­ãƒ¼ã‚»ãƒƒãƒˆã‚’ä½œæˆï¼ˆãƒ•ã‚©ãƒ¼ãƒ ç·¨é›†ã‹ã‚‰é™¤å¤–ã™ã‚‹ãŸã‚ï¼‰
        structured_field_keys = {field["key"] for field in structured_fields}

        # ã‚¿ãƒ–ãƒªã‚¹ãƒˆã‚’å‹•çš„ã«æ§‹ç¯‰
        tab_names = ["ğŸ“ ãƒ•ã‚©ãƒ¼ãƒ ç·¨é›†"]  # ãƒ•ã‚©ãƒ¼ãƒ ç·¨é›†ã‚¿ãƒ–ã®ã¿

        # æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã”ã¨ã«ã‚¿ãƒ–ã‚’è¿½åŠ 
        logger.info(f"ğŸ·ï¸ ã‚¿ãƒ–ç”Ÿæˆ: æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚¿ãƒ–ã‚’ {len(structured_fields)} å€‹è¿½åŠ ã—ã¾ã™")
        for field in structured_fields:
            logger.info(f"  ã‚¿ãƒ–è¿½åŠ : {field['label']} (ã‚­ãƒ¼: {field['key']})")
            tab_names.append(field["label"])

        # å›ºå®šã‚¿ãƒ–ï¼šJSONãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        tab_names.append("ğŸ” JSONãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")

        logger.info(f"ğŸ“‘ ç”Ÿæˆã•ã‚Œã‚‹ã‚¿ãƒ–ä¸€è¦§ ({len(tab_names)} å€‹): {tab_names}")

        # ã‚¿ãƒ–ã‚’å‹•çš„ã«ç”Ÿæˆ
        tabs = st.tabs(tab_names)
        edited_metadata = None

        # ã‚¿ãƒ–1: ãƒ•ã‚©ãƒ¼ãƒ ç·¨é›†
        with tabs[0]:
            if editable_fields:
                # æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ãƒ•ã‚©ãƒ¼ãƒ ã‹ã‚‰é™¤å¤–
                form_fields = [f for f in editable_fields if f["name"] not in structured_field_keys]

                if form_fields:
                    edited_metadata = render_form_editor(metadata, form_fields, doc_id)
                else:
                    st.info("ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯å…¨ã¦å°‚ç”¨ã‚¿ãƒ–ã§ç·¨é›†ã§ãã¾ã™")
                    st.markdown("å„ãƒ‡ãƒ¼ã‚¿ã‚¿ãƒ–ã¾ãŸã¯JSONãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¿ãƒ–ã‚’ã”åˆ©ç”¨ãã ã•ã„")
            else:
                st.info("ãƒ•ã‚©ãƒ¼ãƒ ç·¨é›†ã«ã¯å¯¾å¿œã™ã‚‹ã‚¹ã‚­ãƒ¼ãƒãŒå¿…è¦ã§ã™")

        # ã‚¿ãƒ–2ä»¥é™: æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚¿ãƒ–ï¼ˆå‹•çš„ã«ç”Ÿæˆï¼‰
        for idx, field in enumerate(structured_fields):
            with tabs[idx + 1]:  # ãƒ•ã‚©ãƒ¼ãƒ ç·¨é›†ã®æ¬¡ã‹ã‚‰
                logger.info(f"ğŸ“Š ã‚¿ãƒ– {idx + 1} ã‚’ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°: {field['label']} ({field['key']})")
                logger.info(f"  ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(field['data'])} ä»¶")

                st.markdown(f"### {field['label']}")
                st.markdown("è¡¨å½¢å¼ã§ç·¨é›†ã§ãã¾ã™")
                st.markdown("---")

                # è¡¨ã‚¨ãƒ‡ã‚£ã‚¿ã§ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°
                edited_value = _render_array_table(
                    field["key"],
                    field["data"],
                    field["label"]
                )

                # edited_metadataã‚’åˆæœŸåŒ–ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
                if edited_metadata is None:
                    edited_metadata = metadata.copy()

                edited_metadata[field["key"]] = edited_value
                logger.info(f"  âœ“ {field['label']} ã‚¿ãƒ–ã®ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°å®Œäº†")

        # æœ€å¾Œã®ã‚¿ãƒ–: JSONãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        with tabs[-1]:
            edited_metadata = render_json_preview(metadata, editable=True, key_suffix=doc_id)

        # ä¿å­˜ãƒœã‚¿ãƒ³ã‚¨ãƒªã‚¢
        st.markdown("---")

        # ãƒ¬ãƒ“ãƒ¥ãƒ¼çŠ¶æ…‹ã®è¡¨ç¤º
        is_reviewed = selected_doc.get('is_reviewed', False)
        if is_reviewed:
            reviewed_at = selected_doc.get('reviewed_at', '')
            reviewed_by = selected_doc.get('reviewed_by', '')
            st.info(f"âœ… ãƒ¬ãƒ“ãƒ¥ãƒ¼æ¸ˆã¿ï¼ˆ{reviewed_at[:10] if reviewed_at else 'æ—¥æ™‚ä¸æ˜'}ï¼‰" +
                   (f" by {reviewed_by}" if reviewed_by else ""))

        col_save, col_validate, col_review, col_cancel = st.columns([1, 1, 1, 1])

        with col_validate:
            if st.button("ğŸ” å¤‰æ›´ã‚’ç¢ºèª", use_container_width=True):
                if edited_metadata:
                    with st.expander("å¤‰æ›´å†…å®¹ã®è©³ç´°", expanded=True):
                        render_json_diff(metadata, edited_metadata)

        with col_save:
            if st.button("ğŸ’¾ ä¿å­˜", type="primary", use_container_width=True):
                if edited_metadata is None:
                    st.error("ç·¨é›†ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                else:
                    # ã‚¹ã‚­ãƒ¼ãƒæ¤œè¨¼
                    if detected_schema:
                        is_valid, errors = schema_detector.validate_metadata(detected_schema, edited_metadata)
                        if not is_valid:
                            st.error("âŒ ã‚¹ã‚­ãƒ¼ãƒæ¤œè¨¼ã‚¨ãƒ©ãƒ¼:")
                            for error in errors:
                                st.error(f"  - {error}")
                            st.stop()

                    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ›´æ–°ï¼ˆä¿®æ­£å±¥æ­´ã‚’è¨˜éŒ²ï¼‰
                    success = db_client.record_correction(
                        doc_id=doc_id,
                        new_metadata=edited_metadata,
                        new_doc_type=doc_type,
                        corrector_email=None,  # å°†æ¥çš„ã«èªè¨¼æƒ…å ±ã‹ã‚‰å–å¾—
                        notes="Review UIã‹ã‚‰ã®æ‰‹å‹•ä¿®æ­£"
                    )

                    if success:
                        st.success("âœ… ä¿å­˜ã«æˆåŠŸã—ã¾ã—ãŸï¼ä¿®æ­£å±¥æ­´ãŒè¨˜éŒ²ã•ã‚Œã¾ã—ãŸã€‚")
                        st.balloons()
                        # ãƒšãƒ¼ã‚¸ã‚’ãƒªãƒ­ãƒ¼ãƒ‰
                        st.rerun()
                    else:
                        st.error("âŒ ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ")

        with col_review:
            # ãƒ¬ãƒ“ãƒ¥ãƒ¼çŠ¶æ…‹åˆ‡ã‚Šæ›¿ãˆãƒœã‚¿ãƒ³
            if is_reviewed:
                # ãƒ¬ãƒ“ãƒ¥ãƒ¼æ¸ˆã¿ â†’ æœªå®Œäº†ã«æˆ»ã™
                if st.button("â†©ï¸ æœªå®Œäº†ã«æˆ»ã™", use_container_width=True, type="secondary"):
                    success = db_client.mark_document_unreviewed(doc_id)
                    if success:
                        st.success("âœ… æœªå®Œäº†ã«æˆ»ã—ã¾ã—ãŸ")
                        st.rerun()
                    else:
                        st.error("âŒ æ“ä½œã«å¤±æ•—ã—ã¾ã—ãŸ")
            else:
                # æœªãƒ¬ãƒ“ãƒ¥ãƒ¼ â†’ ãƒã‚§ãƒƒã‚¯å®Œäº†
                if st.button("âœ… ãƒã‚§ãƒƒã‚¯å®Œäº†", use_container_width=True, type="primary"):
                    success = db_client.mark_document_reviewed(doc_id)
                    if success:
                        st.success("âœ… ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†ã¨ã—ã¦ãƒãƒ¼ã‚¯ã—ã¾ã—ãŸ")
                        st.balloons()
                        st.rerun()
                    else:
                        st.error("âŒ æ“ä½œã«å¤±æ•—ã—ã¾ã—ãŸ")

        with col_cancel:
            if st.button("ğŸ”„ ãƒªã‚»ãƒƒãƒˆ", use_container_width=True):
                st.rerun()

    # å‰Šé™¤æ©Ÿèƒ½ï¼ˆå±é™ºãªæ“ä½œã®ãŸã‚ã€åˆ¥ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«é…ç½®ï¼‰
    st.markdown("---")
    st.markdown("### âš ï¸ å±é™ºãªæ“ä½œ")

    # å‰Šé™¤ç¢ºèªç”¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹
    delete_confirm_key = f"delete_confirm_{doc_id}"
    if delete_confirm_key not in st.session_state:
        st.session_state[delete_confirm_key] = False

    col_delete1, col_delete2, col_spacer = st.columns([1, 1, 2])

    with col_delete1:
        if not st.session_state[delete_confirm_key]:
            if st.button("ğŸ—‘ï¸ ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤", use_container_width=True, type="secondary"):
                st.session_state[delete_confirm_key] = True
                st.rerun()
        else:
            st.warning("æœ¬å½“ã«å‰Šé™¤ã—ã¾ã™ã‹ï¼Ÿ")

    with col_delete2:
        if st.session_state[delete_confirm_key]:
            if st.button("âœ… å‰Šé™¤ã‚’å®Ÿè¡Œ", use_container_width=True, type="primary"):
                with st.spinner("å‰Šé™¤ä¸­..."):
                    # 1. ã¾ãšGoogle Driveã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚´ãƒŸç®±ã«ç§»å‹•
                    drive_success = False
                    if file_id:
                        try:
                            drive_connector = GoogleDriveConnector()
                            drive_success = drive_connector.trash_file(file_id)
                            if drive_success:
                                st.success(f"âœ… Google Driveã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚´ãƒŸç®±ã«ç§»å‹•ã—ã¾ã—ãŸ")
                            else:
                                st.warning(f"âš ï¸ Google Driveãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸãŒã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã¯å‰Šé™¤ã—ã¾ã™")
                        except Exception as e:
                            st.error(f"Google Driveå‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
                            st.warning(f"âš ï¸ Google Driveãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸãŒã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã¯å‰Šé™¤ã—ã¾ã™")
                    else:
                        st.warning("Google Driveã®ãƒ•ã‚¡ã‚¤ãƒ«IDãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã¿å‰Šé™¤ã—ã¾ã™ã€‚")

                    # 2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å‰Šé™¤
                    db_success = db_client.delete_document(doc_id)

                    if db_success:
                        st.success("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
                        st.balloons()
                        # å‰Šé™¤ç¢ºèªçŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
                        st.session_state[delete_confirm_key] = False
                        # å°‘ã—å¾…ã£ã¦ã‹ã‚‰ãƒªãƒ­ãƒ¼ãƒ‰
                        import time
                        time.sleep(1)
                        st.rerun()
                    else:
                        st.error("âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã®å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ")
                        st.session_state[delete_confirm_key] = False

            if st.button("âŒ ã‚­ãƒ£ãƒ³ã‚»ãƒ«", use_container_width=True):
                st.session_state[delete_confirm_key] = False
                st.rerun()

    # ãƒ•ãƒƒã‚¿ãƒ¼
    st.markdown("---")
    col_footer1, col_footer2 = st.columns([3, 1])
    with col_footer1:
        st.caption("Document Management System - Review UI v2.0 (Tab Edition)")
    with col_footer2:
        st.caption(f"ğŸ¨ æ¤œå‡ºã‚¹ã‚­ãƒ¼ãƒ: {detected_schema or 'N/A'}")


def main():
    """ãƒ¡ã‚¤ãƒ³UIãƒ­ã‚¸ãƒƒã‚¯ - ã‚¿ãƒ–åˆ‡ã‚Šæ›¿ãˆ"""
    st.set_page_config(
        page_title="Document Management System",
        page_icon="ğŸ“š",
        layout="wide",
        initial_sidebar_state="expanded"
    )

    st.title("ğŸ“š Document Management System")
    st.markdown("PDFãƒ¬ãƒ“ãƒ¥ãƒ¼ã¨ãƒ¡ãƒ¼ãƒ«å—ä¿¡ãƒˆãƒ¬ã‚¤ã‚’çµ±åˆç®¡ç†")

    # ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã®ã‚¿ãƒ–
    tab1, tab2 = st.tabs(["ğŸ“‹ PDFãƒ¬ãƒ“ãƒ¥ãƒ¼", "ğŸ“¬ ãƒ¡ãƒ¼ãƒ«å—ä¿¡ãƒˆãƒ¬ã‚¤"])

    with tab1:
        pdf_review_ui()

    with tab2:
        # ãƒ¡ãƒ¼ãƒ«UIã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦è¡¨ç¤º
        from ui.email_inbox import email_inbox_ui
        email_inbox_ui()


if __name__ == "__main__":
    main()
