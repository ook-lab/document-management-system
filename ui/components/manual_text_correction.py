"""
æ‰‹å‹•ãƒ†ã‚­ã‚¹ãƒˆè£œæ­£ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ (Human-in-the-loop)

Gemini VisionãŒå–ã‚Šã“ã¼ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’äººé–“ãŒè£œå®Œã—ã€
Stage 2ï¼ˆClaude 4.5 Haikuï¼‰ã§å†æ§‹é€ åŒ–ã™ã‚‹æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚

ä½¿ç”¨ä¾‹:
- ã‚¹ã‚­ãƒ£ãƒ³PDFã§500æ–‡å­—ã®ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚‹
- Gemini VisionãŒä¸€éƒ¨ã—ã‹æ‹¾ãˆãªã‹ã£ãŸï¼ˆ200æ–‡å­—ï¼‰
- äººé–“ãŒæ®‹ã‚Šã®300æ–‡å­—ã‚’æ‰‹å…¥åŠ›
- å®Œå…¨ãªãƒ†ã‚­ã‚¹ãƒˆï¼ˆ500æ–‡å­—ï¼‰+ Gemini Visionã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæƒ…å ±ã§Stage 2å†å®Ÿè¡Œ
- â†’ é«˜å“è³ªãªæ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ãŒç”Ÿæˆã•ã‚Œã‚‹
"""
import streamlit as st
from typing import Dict, Any, Optional
from loguru import logger
import difflib


def _highlight_diff(original: str, corrected: str) -> str:
    """
    2ã¤ã®ãƒ†ã‚­ã‚¹ãƒˆã®å·®åˆ†ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤ºç”¨ã®ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã«å¤‰æ›

    Args:
        original: å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆ
        corrected: è£œæ­£å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆ

    Returns:
        å·®åˆ†ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆã—ãŸãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³æ–‡å­—åˆ—
    """
    diff = list(difflib.unified_diff(
        original.split('\n'),
        corrected.split('\n'),
        lineterm='',
        n=0  # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¡Œæ•°ã‚’0ã«
    ))

    if not diff:
        return "ï¼ˆå¤‰æ›´ãªã—ï¼‰"

    result_lines = []
    for line in diff[2:]:  # æœ€åˆã®2è¡Œã¯ãƒ˜ãƒƒãƒ€ãƒ¼ãªã®ã§ã‚¹ã‚­ãƒƒãƒ—
        if line.startswith('+'):
            result_lines.append(f"**+ {line[1:]}**")  # è¿½åŠ è¡Œã‚’å¤ªå­—
        elif line.startswith('-'):
            result_lines.append(f"~~- {line[1:]}~~")  # å‰Šé™¤è¡Œã‚’å–ã‚Šæ¶ˆã—ç·š
        else:
            result_lines.append(line)

    return '\n'.join(result_lines)


def render_manual_text_correction(
    doc_id: str,
    file_name: str,
    extracted_text: str,
    metadata: Dict[str, Any],
    doc_type: str
) -> Optional[str]:
    """
    æ‰‹å‹•ãƒ†ã‚­ã‚¹ãƒˆè£œæ­£UIã‚’ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°

    ã“ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã¯ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ï¼š
    1. Gemini VisionãŒæŠ½å‡ºã—ãŸãƒ†ã‚­ã‚¹ãƒˆã®è¡¨ç¤º
    2. äººé–“ã«ã‚ˆã‚‹æ‰‹å‹•è£œæ­£ãƒ»å®Œå…¨å…¥åŠ›
    3. è£œæ­£å‰å¾Œã®å·®åˆ†è¡¨ç¤º
    4. Stage 2å†å®Ÿè¡Œãƒœã‚¿ãƒ³

    Args:
        doc_id: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆID
        file_name: ãƒ•ã‚¡ã‚¤ãƒ«å
        extracted_text: Gemini VisionãŒæŠ½å‡ºã—ãŸãƒ†ã‚­ã‚¹ãƒˆ
        metadata: æ—¢å­˜ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆStage 1ã®çµæœã‚’å«ã‚€ï¼‰
        doc_type: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒ—

    Returns:
        è£œæ­£ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆï¼ˆå†å®Ÿè¡ŒãŒè¦æ±‚ã•ã‚ŒãŸå ´åˆï¼‰ã€ã¾ãŸã¯None
    """
    st.markdown("---")
    st.markdown("### ğŸ› ï¸ ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã®æ‰‹å‹•è£œæ­£ï¼ˆHuman-in-the-loopï¼‰")

    # èª¬æ˜ã‚¨ãƒªã‚¢
    with st.expander("ğŸ’¡ ã“ã®æ©Ÿèƒ½ã«ã¤ã„ã¦", expanded=False):
        st.markdown("""
        **Gemini VisionãŒå–ã‚Šã“ã¼ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’è£œå®Œã§ãã¾ã™ï¼**

        **ä½¿ç”¨ä¾‹:**
        - ã‚¹ã‚­ãƒ£ãƒ³ã•ã‚ŒãŸPDFã§ã€OCRãŒä¸€éƒ¨ã®æ–‡å­—ã‚’èª­ã‚ãªã‹ã£ãŸå ´åˆ
        - æ‰‹æ›¸ãæ–‡å­—ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆ
        - è¤‡é›‘ãªãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã§æŠ½å‡ºãŒä¸å®Œå…¨ãªå ´åˆ

        **å‡¦ç†ãƒ•ãƒ­ãƒ¼:**
        1. ğŸ‘‡ ä¸‹ã®ã‚¨ãƒªã‚¢ã«æ­£ã—ã„ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„
        2. ğŸ”„ ã€Œå†æ§‹é€ åŒ–ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¨...
        3. **å®Œå…¨ãªãƒ†ã‚­ã‚¹ãƒˆï¼ˆäººé–“ï¼‰+ ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæƒ…å ±ï¼ˆVisionï¼‰** ã§Stage 2ãŒå†å®Ÿè¡Œã•ã‚Œã¾ã™
        4. âœ¨ æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã®å“è³ªãŒãƒ¬ãƒ™ãƒ«ã‚¢ãƒƒãƒ—ï¼

        **ãƒã‚¤ãƒ³ãƒˆ:**
        - Gemini Visionã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæƒ…å ±ï¼ˆè¦‹å‡ºã—ã€ç®‡æ¡æ›¸ããªã©ã®æ§‹é€ ï¼‰ã¯ä¿æŒã•ã‚Œã¾ã™
        - Claude 4.5 HaikuãŒã€å®Œå…¨ãªãƒ†ã‚­ã‚¹ãƒˆã¨ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæƒ…å ±ã‚’çµ±åˆã—ã¦æ§‹é€ åŒ–ã—ã¾ã™
        """)

    # ç¾åœ¨ã®æŠ½å‡ºçŠ¶æ³
    col_info1, col_info2, col_info3 = st.columns(3)
    with col_info1:
        st.metric("å…ƒã®æ–‡å­—æ•°", len(extracted_text))
    with col_info2:
        stage1_confidence = metadata.get('stage1_confidence', 0)
        st.metric("Stage 1 ä¿¡é ¼åº¦", f"{stage1_confidence:.2%}")
    with col_info3:
        st.metric("ãƒ•ã‚¡ã‚¤ãƒ«å", file_name[:20] + "..." if len(file_name) > 20 else file_name)

    # Stage 1ã®æƒ…å ±ã‚’è¡¨ç¤º
    with st.expander("ğŸ” Gemini Visionã®è§£ææƒ…å ±ï¼ˆä¿æŒã•ã‚Œã‚‹ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæƒ…å ±ï¼‰"):
        st.json({
            "doc_type": doc_type,
            "summary": metadata.get('summary', '')[:200] + "...",
            "relevant_date": metadata.get('relevant_date'),
            "confidence": metadata.get('stage1_confidence', 0)
        })

    st.markdown("---")

    # ã‚¿ãƒ–ã§ç·¨é›†æ–¹æ³•ã‚’é¸æŠ
    tab1, tab2, tab3 = st.tabs(["ğŸ“ å…¨æ–‡ç·¨é›†", "âœï¸ è¡Œå˜ä½ç·¨é›†", "ğŸ“Š å·®åˆ†ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼"])

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã§ãƒ†ã‚­ã‚¹ãƒˆã‚’ç®¡ç†
    if f'corrected_text_{doc_id}' not in st.session_state:
        st.session_state[f'corrected_text_{doc_id}'] = extracted_text

    corrected_text = None

    with tab1:
        st.markdown("#### å…¨æ–‡ã‚’ç·¨é›†")
        st.info("ğŸ’¡ å–ã‚Šã“ã¼ã•ã‚ŒãŸæ–‡å­—ã‚’è¿½åŠ ã™ã‚‹ã‹ã€ãƒ†ã‚­ã‚¹ãƒˆå…¨ä½“ã‚’æ›¸ãç›´ã—ã¦ãã ã•ã„")

        user_input = st.text_area(
            "ãƒ†ã‚­ã‚¹ãƒˆã®æ‰‹å‹•å…¥åŠ›ãƒ»è£œæ­£",
            value=st.session_state[f'corrected_text_{doc_id}'],
            height=400,
            key=f"manual_text_full_{doc_id}",
            help="Gemini VisionãŒå–ã‚Šã“ã¼ã—ãŸæ–‡å­—ã‚’è¿½åŠ ã—ã¦ãã ã•ã„"
        )

        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—æ•°è¡¨ç¤º
        char_diff = len(user_input) - len(extracted_text)
        if char_diff > 0:
            st.success(f"âœ… {char_diff} æ–‡å­—è¿½åŠ ã•ã‚Œã¾ã—ãŸï¼ˆåˆè¨ˆ: {len(user_input)} æ–‡å­—ï¼‰")
        elif char_diff < 0:
            st.warning(f"âš ï¸ {abs(char_diff)} æ–‡å­—å‰Šé™¤ã•ã‚Œã¾ã—ãŸï¼ˆåˆè¨ˆ: {len(user_input)} æ–‡å­—ï¼‰")
        else:
            st.info("å¤‰æ›´ãªã—")

        st.session_state[f'corrected_text_{doc_id}'] = user_input

    with tab2:
        st.markdown("#### è¡Œå˜ä½ã§ç·¨é›†")
        st.info("ğŸ’¡ å„è¡Œã‚’å€‹åˆ¥ã«ç·¨é›†ã§ãã¾ã™ã€‚é–“é•ã£ã¦ã„ã‚‹è¡Œã ã‘ã‚’ä¿®æ­£ã—ã¦ãã ã•ã„")

        lines = extracted_text.split('\n')
        edited_lines = []

        for i, line in enumerate(lines):
            col1, col2 = st.columns([1, 20])
            with col1:
                st.markdown(f"`{i+1:02d}`")
            with col2:
                edited_line = st.text_input(
                    f"è¡Œ {i+1}",
                    value=line,
                    key=f"line_{doc_id}_{i}",
                    label_visibility="collapsed"
                )
                edited_lines.append(edited_line)

        # è¡Œç·¨é›†ã®çµæœã‚’åæ˜ 
        line_edited_text = "\n".join(edited_lines)
        st.session_state[f'corrected_text_{doc_id}'] = line_edited_text

        # å¤‰æ›´è¡Œæ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        changed_lines = sum(1 for orig, edit in zip(lines, edited_lines) if orig != edit)
        if changed_lines > 0:
            st.success(f"âœ… {changed_lines} è¡ŒãŒå¤‰æ›´ã•ã‚Œã¾ã—ãŸ")

    with tab3:
        st.markdown("#### å¤‰æ›´å†…å®¹ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        st.info("ğŸ’¡ å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã¨è£œæ­£å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆã®å·®åˆ†ã‚’ç¢ºèªã§ãã¾ã™")

        current_text = st.session_state[f'corrected_text_{doc_id}']

        if current_text != extracted_text:
            st.markdown("**å·®åˆ†:**")
            diff_markdown = _highlight_diff(extracted_text, current_text)
            st.markdown(diff_markdown)

            # çµ±è¨ˆæƒ…å ±
            col_stat1, col_stat2 = st.columns(2)
            with col_stat1:
                st.metric("å…ƒã®æ–‡å­—æ•°", len(extracted_text))
            with col_stat2:
                st.metric("è£œæ­£å¾Œã®æ–‡å­—æ•°", len(current_text))
        else:
            st.info("å¤‰æ›´ãŒã‚ã‚Šã¾ã›ã‚“")

    st.markdown("---")

    # å†å®Ÿè¡Œãƒœã‚¿ãƒ³
    col_btn1, col_btn2, col_btn3 = st.columns([2, 2, 6])

    with col_btn1:
        if st.button(
            "ğŸ”„ Stage 2 å†å®Ÿè¡Œ",
            type="primary",
            use_container_width=True,
            key=f"reprocess_{doc_id}",
            help="è£œæ­£ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã§Claude 4.5 Haikuã«ã‚ˆã‚‹æ§‹é€ åŒ–ã‚’å†å®Ÿè¡Œã—ã¾ã™"
        ):
            current_text = st.session_state[f'corrected_text_{doc_id}']
            if current_text != extracted_text:
                corrected_text = current_text
                logger.info(f"[æ‰‹å‹•è£œæ­£] ãƒ†ã‚­ã‚¹ãƒˆè£œæ­£å®Œäº†: {len(extracted_text)} â†’ {len(corrected_text)} æ–‡å­—")
            else:
                st.warning("âš ï¸ ãƒ†ã‚­ã‚¹ãƒˆãŒå¤‰æ›´ã•ã‚Œã¦ã„ã¾ã›ã‚“")

    with col_btn2:
        if st.button(
            "â†©ï¸ ãƒªã‚»ãƒƒãƒˆ",
            use_container_width=True,
            key=f"reset_{doc_id}",
            help="å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã«æˆ»ã—ã¾ã™"
        ):
            st.session_state[f'corrected_text_{doc_id}'] = extracted_text
            st.rerun()

    return corrected_text


def execute_stage2_reprocessing(
    corrected_text: str,
    file_name: str,
    metadata: Dict[str, Any],
    workspace: str
) -> Dict[str, Any]:
    """
    è£œæ­£ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã§Stage 2ã‚’å†å®Ÿè¡Œ

    ã“ã®ãƒ©ãƒƒãƒ‘ãƒ¼é–¢æ•°ã¯å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã«æ®‹ã•ã‚Œã¦ã„ã¾ã™ã€‚
    æ–°ã—ã„ã‚³ãƒ¼ãƒ‰ã§ã¯ ui.utils.stage2_reprocessor ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚

    Args:
        corrected_text: äººé–“ãŒè£œæ­£ã—ãŸãƒ†ã‚­ã‚¹ãƒˆ
        file_name: ãƒ•ã‚¡ã‚¤ãƒ«å
        metadata: Stage 1ã®çµæœã‚’å«ã‚€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        workspace: ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹

    Returns:
        æ–°ã—ã„æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿
    """
    from ui.utils.stage2_reprocessor import reprocess_with_stageC
    from A_common.database.client import DatabaseClient

    logger.warning("[Deprecated] execute_stage2_reprocessing() ã¯éæ¨å¥¨ã§ã™ã€‚ui.utils.stage2_reprocessor.reprocess_with_stageC() ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚")

    # ã“ã®é–¢æ•°ã¯å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã«æ®‹ã•ã‚Œã¦ã„ã¾ã™ãŒã€æ–°ã—ã„ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’å†…éƒ¨ã§ä½¿ç”¨ã—ã¾ã™
    # æˆ»ã‚Šå€¤ã®å½¢å¼ã‚’ç¶­æŒã™ã‚‹ãŸã‚ã€ãƒ©ãƒƒãƒ‘ãƒ¼ã¨ã—ã¦æ©Ÿèƒ½ã—ã¾ã™
    from F_stage_c_extractor.extractor import StageCExtractor
    from C_ai_common.llm_client.llm_client import LLMClient

    logger.info("[Stage 2 å†å®Ÿè¡Œ] é–‹å§‹...")
    logger.info(f"  è£œæ­£ãƒ†ã‚­ã‚¹ãƒˆ: {len(corrected_text)} æ–‡å­—")
    logger.info(f"  Workspace: {workspace}")

    # Stage 1ã®çµæœã‚’å¾©å…ƒ
    stage1_result = {
        "doc_type": metadata.get('doc_type', 'other'),
        "summary": metadata.get('summary', ''),
        "relevant_date": metadata.get('relevant_date'),
        "confidence": metadata.get('stage1_confidence', 0.0)
    }

    # Stage 2 Extractorã‚’åˆæœŸåŒ–
    llm_client = LLMClient()
    extractor = StageCExtractor(llm_client=llm_client)

    # Stage 2å†å®Ÿè¡Œ
    stage2_result = extractor.extract_metadata(
        attachment_text=corrected_text,
        file_name=file_name,
        stage1_result=stage1_result,
        workspace=workspace
    )

    logger.info(f"[Stage 2 å†å®Ÿè¡Œ] å®Œäº†: ä¿¡é ¼åº¦={stage2_result.get('extraction_confidence', 0):.2f}")

    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°
    new_metadata = {
        **metadata,
        **stage2_result.get('metadata', {}),
        'manually_corrected': True,
        'correction_timestamp': __import__('datetime').datetime.now().isoformat(),
        'corrected_text_length': len(corrected_text)
    }

    return {
        'summary': stage2_result.get('summary'),
        'document_date': stage2_result.get('document_date'),
        'tags': stage2_result.get('tags', []),
        'metadata': new_metadata,
        'confidence': stage2_result.get('extraction_confidence', 0.0)
    }
