"""
ãƒãƒ©ã‚·å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

flyer_documentsãƒ†ãƒ¼ãƒ–ãƒ«ã® processing_status='pending' ã®ãƒãƒ©ã‚·ã‚’å‡¦ç†

å‡¦ç†ãƒ•ãƒ­ãƒ¼:
1. Pre-processing: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
2. Stage B (Gemini Vision):
   - Step 1: OCR + ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè§£æ
   - Step 2: å•†å“æƒ…å ±ã®æ§‹é€ åŒ–æŠ½å‡º
3. Stage C (Haiku): æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã®æœ€çµ‚æ•´ç†
4. Stage A (Gemini): è¦ç´„ç”Ÿæˆ
5. ãƒãƒ£ãƒ³ã‚¯åŒ–ãƒ»ãƒ™ã‚¯ãƒˆãƒ«åŒ–: search_indexã«ä¿å­˜

ä½¿ã„æ–¹:
    # å…¨ã¦ã®pendingãƒãƒ©ã‚·ã‚’å‡¦ç†ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ10ä»¶ï¼‰
    python process_queued_flyers.py

    # å‡¦ç†ä»¶æ•°ã‚’æŒ‡å®š
    python process_queued_flyers.py --limit=50

    # ç‰¹å®šã®åº—èˆ—ã®ã¿å‡¦ç†
    python process_queued_flyers.py --store="ãƒ•ãƒ¼ãƒ‡ã‚£ã‚¢ãƒ  æ­¦è”µå°æ‰"

    # ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ï¼ˆç¢ºèªã®ã¿ï¼‰
    python process_queued_flyers.py --dry-run
"""

import asyncio
import sys
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime
from loguru import logger
import hashlib

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
root_dir = Path(__file__).parent
sys.path.insert(0, str(root_dir))

from A_common.database.client import DatabaseClient
from A_common.connectors.google_drive import GoogleDriveConnector
from C_ai_common.llm_client.llm_client import LLMClient
from E_stage_b_vision.flyer_vision_processor import FlyerVisionProcessor
from F_stage_c_extractor.extractor import StageCExtractor
from D_stage_a_classifier.classifier import StageAClassifier
from A_common.processing.metadata_chunker import MetadataChunker


class FlyerProcessor:
    """ãƒãƒ©ã‚·å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""

    def __init__(self, temp_dir: str = "./temp"):
        """
        Args:
            temp_dir: ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        self.db = DatabaseClient()
        self.drive = GoogleDriveConnector()
        self.llm_client = LLMClient()

        self.vision_processor = FlyerVisionProcessor(llm_client=self.llm_client)
        self.stagec_extractor = StageCExtractor(llm_client=self.llm_client)
        self.stagea_classifier = StageAClassifier(llm_client=self.llm_client)

        self.temp_dir = Path(temp_dir)
        self.temp_dir.mkdir(parents=True, exist_ok=True)

        logger.info("FlyerProcessoråˆæœŸåŒ–å®Œäº†")

    def get_pending_flyers(
        self,
        limit: int = 10,
        store_name: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """
        å‡¦ç†å¾…ã¡ã®ãƒãƒ©ã‚·ã‚’å–å¾—

        Args:
            limit: å–å¾—ä»¶æ•°
            store_name: åº—èˆ—åï¼ˆæŒ‡å®šã•ã‚ŒãŸå ´åˆã®ã¿ï¼‰

        Returns:
            ãƒãƒ©ã‚·æƒ…å ±ã®ãƒªã‚¹ãƒˆ
        """
        try:
            query = self.db.client.table('flyer_documents').select('*').eq(
                'processing_status', 'pending'
            )

            if store_name:
                query = query.eq('organization', store_name)

            result = query.limit(limit).execute()

            if result.data:
                logger.info(f"å‡¦ç†å¾…ã¡ãƒãƒ©ã‚·: {len(result.data)}ä»¶")
                return result.data

            return []

        except Exception as e:
            logger.error(f"ãƒãƒ©ã‚·å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []

    async def process_single_flyer(
        self,
        flyer_doc: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        1ä»¶ã®ãƒãƒ©ã‚·ã‚’å‡¦ç†

        Args:
            flyer_doc: ãƒãƒ©ã‚·ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæƒ…å ±

        Returns:
            å‡¦ç†çµæœ
        """
        flyer_doc_id = flyer_doc['id']
        file_name = flyer_doc.get('file_name', 'ä¸æ˜')
        source_id = flyer_doc.get('source_id')  # Google Drive ID
        organization = flyer_doc.get('organization', 'ä¸æ˜')

        logger.info(f"\n{'='*80}")
        logger.info(f"ãƒãƒ©ã‚·å‡¦ç†é–‹å§‹: {file_name}")
        logger.info(f"  åº—èˆ—: {organization}")
        logger.info(f"  ID: {flyer_doc_id}")
        logger.info(f"{'='*80}")

        result = {
            'flyer_doc_id': flyer_doc_id,
            'file_name': file_name,
            'success': False,
            'products_count': 0,
            'chunks_count': 0,
            'error': None
        }

        local_path = None

        try:
            # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ 'processing' ã«æ›´æ–°
            self._update_status(flyer_doc_id, 'processing')

            # ============================================
            # Pre-processing: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            # ============================================
            logger.info("[Pre-processing] ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
            local_path = self.drive.download_file(source_id, file_name, self.temp_dir)

            if not local_path or not Path(local_path).exists():
                raise Exception("ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—")

            logger.info(f"  ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {local_path}")

            # ============================================
            # Stage B: Gemini Visionï¼ˆ2æ®µéšå‡¦ç†ï¼‰
            # ============================================
            logger.info("[Stage B] Gemini Visionå‡¦ç†é–‹å§‹...")

            flyer_metadata = {
                'organization': organization,
                'flyer_title': flyer_doc.get('flyer_title'),
                'flyer_period': flyer_doc.get('flyer_period'),
                'page_number': flyer_doc.get('page_number')
            }

            vision_result = await self.vision_processor.process_flyer_image(
                image_path=Path(local_path),
                flyer_metadata=flyer_metadata
            )

            if not vision_result.get('success'):
                raise Exception(f"Visionå‡¦ç†å¤±æ•—: {vision_result.get('error')}")

            step1_result = vision_result['step1_result']
            step2_result = vision_result['step2_result']

            full_text = step1_result.get('full_text', '')
            products = step2_result.get('products', [])

            logger.info(f"[Stage Bå®Œäº†] ãƒ†ã‚­ã‚¹ãƒˆ: {len(full_text)}æ–‡å­—, å•†å“: {len(products)}ä»¶")

            # ============================================
            # Stage C: Haikuæ§‹é€ åŒ–
            # ============================================
            logger.info("[Stage C] Haikuæ§‹é€ åŒ–é–‹å§‹...")

            stagec_result = self.stagec_extractor.extract_metadata(
                file_name=file_name,
                stage1_result={
                    'doc_type': 'physical shop',
                    'workspace': 'shopping'
                },
                workspace='shopping',
                attachment_text=full_text
            )

            document_date = stagec_result.get('document_date')
            tags = stagec_result.get('tags', [])
            stagec_metadata = stagec_result.get('metadata', {})

            logger.info(f"[Stage Cå®Œäº†] metadata_fields={len(stagec_metadata)}")

            # ============================================
            # å•†å“æƒ…å ±ã‚’flyer_productsãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜
            # ============================================
            logger.info("[å•†å“ä¿å­˜] flyer_productsãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜ä¸­...")

            saved_products = await self._save_products(
                flyer_doc_id=flyer_doc_id,
                products=products,
                page_number=flyer_doc.get('page_number', 1)
            )

            result['products_count'] = saved_products
            logger.info(f"  ä¿å­˜å®Œäº†: {saved_products}ä»¶")

            # ============================================
            # Stage A: Geminiè¦ç´„
            # ============================================
            logger.info("[Stage A] Geminiè¦ç´„é–‹å§‹...")

            summary = ''
            try:
                stageA_result = await self.stagea_classifier.classify(
                    file_path=Path(local_path),
                    doc_types_yaml="",  # ãƒãƒ©ã‚·ã¯åˆ†é¡ä¸è¦
                    mime_type="image/jpeg",
                    text_content=full_text,
                    stagec_result=stagec_result
                )

                summary = stageA_result.get('summary', '')
                logger.info(f"[Stage Aå®Œäº†] summary={summary[:50] if summary else ''}...")

            except Exception as e:
                logger.error(f"[Stage A] ã‚¨ãƒ©ãƒ¼: {e}")
                summary = stagec_result.get('summary', '')

            # ============================================
            # flyer_documentsãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ›´æ–°
            # ============================================
            logger.info("[æ›´æ–°] flyer_documentsãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ›´æ–°ä¸­...")

            update_data = {
                'attachment_text': full_text,
                'summary': summary,
                'metadata': {
                    **stagec_metadata,
                    'step1_ocr': step1_result,
                    'extraction_notes': step2_result.get('extraction_notes')
                },
                'tags': tags,
                'document_date': document_date,
                'processing_status': 'completed',
                'processing_stage': 'products_extracted',
                'stageb_vision_model': 'gemini-2.0-flash-exp',
                'stagec_extractor_model': 'claude-haiku-4-5-20251001',
                'stagea_classifier_model': 'gemini-2.5-flash'
            }

            self.db.client.table('flyer_documents').update(update_data).eq(
                'id', flyer_doc_id
            ).execute()

            # ============================================
            # ãƒãƒ£ãƒ³ã‚¯åŒ–ãƒ»ãƒ™ã‚¯ãƒˆãƒ«åŒ–
            # ============================================
            logger.info("[ãƒãƒ£ãƒ³ã‚¯åŒ–] search_indexã«ä¿å­˜ä¸­...")

            # æ—¢å­˜ãƒãƒ£ãƒ³ã‚¯å‰Šé™¤
            try:
                delete_result = self.db.client.table('search_index').delete().eq(
                    'document_id', flyer_doc_id
                ).execute()
                deleted_count = len(delete_result.data) if delete_result.data else 0
                logger.info(f"  æ—¢å­˜ãƒãƒ£ãƒ³ã‚¯å‰Šé™¤: {deleted_count}å€‹")
            except Exception as e:
                logger.warning(f"  æ—¢å­˜ãƒãƒ£ãƒ³ã‚¯å‰Šé™¤ã‚¨ãƒ©ãƒ¼ï¼ˆç¶™ç¶šï¼‰: {e}")

            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒãƒ£ãƒ³ã‚¯ç”Ÿæˆ
            metadata_chunker = MetadataChunker()

            document_data = {
                'file_name': file_name,
                'summary': summary,
                'document_date': document_date,
                'tags': tags,
                'doc_type': 'physical shop',
                'display_subject': flyer_doc.get('flyer_title'),
                'display_sender': organization,
                'display_sent_at': flyer_doc.get('created_at'),
                'persons': stagec_metadata.get('persons', []),
                'organizations': [organization],
                'attachment_text': full_text
            }

            metadata_chunks = metadata_chunker.create_metadata_chunks(document_data)

            current_chunk_index = 0
            for meta_chunk in metadata_chunks:
                meta_text = meta_chunk.get('chunk_text', '')
                meta_type = meta_chunk.get('chunk_type', 'metadata')
                meta_weight = meta_chunk.get('search_weight', 1.0)

                if not meta_text:
                    continue

                # Embeddingç”Ÿæˆ
                meta_embedding = self.llm_client.generate_embedding(meta_text)

                # search_indexã«ä¿å­˜
                meta_doc = {
                    'document_id': flyer_doc_id,
                    'chunk_index': current_chunk_index,
                    'chunk_content': meta_text,
                    'chunk_size': len(meta_text),
                    'chunk_type': meta_type,
                    'embedding': meta_embedding,
                    'search_weight': meta_weight
                }

                try:
                    await self.db.insert_document('search_index', meta_doc)
                    current_chunk_index += 1
                except Exception as e:
                    logger.error(f"  ãƒãƒ£ãƒ³ã‚¯ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

            result['chunks_count'] = current_chunk_index
            logger.info(f"  ãƒãƒ£ãƒ³ã‚¯ä¿å­˜å®Œäº†: {current_chunk_index}å€‹")

            # ãƒãƒ£ãƒ³ã‚¯æ•°ã‚’æ›´æ–°
            self.db.client.table('flyer_documents').update({
                'chunk_count': current_chunk_index
            }).eq('id', flyer_doc_id).execute()

            result['success'] = True
            logger.success(f"âœ… ãƒãƒ©ã‚·å‡¦ç†å®Œäº†: {file_name}")
            logger.info(f"  å•†å“: {saved_products}ä»¶, ãƒãƒ£ãƒ³ã‚¯: {current_chunk_index}å€‹")

        except Exception as e:
            error_msg = str(e)
            logger.error(f"âŒ ãƒãƒ©ã‚·å‡¦ç†ã‚¨ãƒ©ãƒ¼: {error_msg}", exc_info=True)

            self._update_status(
                flyer_doc_id,
                'failed',
                error=error_msg
            )
            result['error'] = error_msg

        finally:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            if local_path and Path(local_path).exists():
                Path(local_path).unlink()
                logger.debug(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤: {local_path}")

        return result

    async def _save_products(
        self,
        flyer_doc_id: str,
        products: List[Dict[str, Any]],
        page_number: int
    ) -> int:
        """
        å•†å“æƒ…å ±ã‚’flyer_productsãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜

        Args:
            flyer_doc_id: ãƒãƒ©ã‚·ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆID
            products: å•†å“ãƒªã‚¹ãƒˆ
            page_number: ãƒšãƒ¼ã‚¸ç•ªå·

        Returns:
            ä¿å­˜æˆåŠŸä»¶æ•°
        """
        success_count = 0

        for product in products:
            try:
                # å•†å“åã®æ­£è¦åŒ–ï¼ˆæ¤œç´¢ç”¨ï¼‰
                product_name = product.get('product_name', '')
                product_name_normalized = product_name.lower().strip()

                product_data = {
                    'flyer_document_id': flyer_doc_id,
                    'product_name': product_name,
                    'product_name_normalized': product_name_normalized,
                    'price': product.get('price'),
                    'original_price': product.get('original_price'),
                    'discount_rate': product.get('discount_rate'),
                    'price_unit': product.get('price_unit', 'å††'),
                    'price_text': product.get('price_text'),
                    'category': product.get('category', 'ãã®ä»–'),
                    'subcategory': product.get('subcategory'),
                    'brand': product.get('brand'),
                    'quantity': product.get('quantity'),
                    'origin': product.get('origin'),
                    'is_special_offer': product.get('is_special_offer', False),
                    'offer_type': product.get('offer_type'),
                    'page_number': page_number,
                    'extracted_text': product.get('extracted_text'),
                    'confidence': product.get('confidence', 0.5),
                    'metadata': {
                        'extraction_date': datetime.now().isoformat(),
                        'extraction_model': 'gemini-2.0-flash-exp'
                    }
                }

                result = await self.db.insert_document('flyer_products', product_data)
                if result:
                    success_count += 1

            except Exception as e:
                logger.error(f"å•†å“ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
                logger.debug(f"å•†å“ãƒ‡ãƒ¼ã‚¿: {product}")

        return success_count

    def _update_status(
        self,
        flyer_doc_id: str,
        status: str,
        error: str = None
    ):
        """
        ãƒãƒ©ã‚·ã®å‡¦ç†ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’æ›´æ–°

        Args:
            flyer_doc_id: ãƒãƒ©ã‚·ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆID
            status: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ï¼ˆprocessing, completed, failedï¼‰
            error: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        """
        try:
            update_data = {
                'processing_status': status,
                'updated_at': datetime.now().isoformat()
            }

            if error:
                update_data['processing_error'] = error

            self.db.client.table('flyer_documents').update(update_data).eq(
                'id', flyer_doc_id
            ).execute()

        except Exception as e:
            logger.error(f"ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")

    async def process_pending_flyers(
        self,
        limit: int = 10,
        store_name: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        å‡¦ç†å¾…ã¡ã®ãƒãƒ©ã‚·ã‚’ä¸€æ‹¬å‡¦ç†

        Args:
            limit: å‡¦ç†ä»¶æ•°
            store_name: åº—èˆ—åï¼ˆæŒ‡å®šã•ã‚ŒãŸå ´åˆã®ã¿ï¼‰

        Returns:
            å‡¦ç†çµæœã®ã‚µãƒãƒªãƒ¼
        """
        logger.info("=" * 80)
        logger.info("ãƒãƒ©ã‚·å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é–‹å§‹")
        logger.info("=" * 80)

        # å‡¦ç†å¾…ã¡ãƒãƒ©ã‚·ã‚’å–å¾—
        pending_flyers = self.get_pending_flyers(limit, store_name)

        if not pending_flyers:
            logger.info("å‡¦ç†å¾…ã¡ã®ãƒãƒ©ã‚·ã¯ã‚ã‚Šã¾ã›ã‚“")
            return {'total': 0, 'success': 0, 'failed': 0}

        logger.info(f"å‡¦ç†å¯¾è±¡: {len(pending_flyers)}ä»¶")

        results = []
        for i, flyer in enumerate(pending_flyers, 1):
            logger.info(f"\n[{i}/{len(pending_flyers)}] å‡¦ç†ä¸­...")
            result = await self.process_single_flyer(flyer)
            results.append(result)

        # ã‚µãƒãƒªãƒ¼
        success_count = sum(1 for r in results if r['success'])
        failed_count = len(results) - success_count
        total_products = sum(r.get('products_count', 0) for r in results)
        total_chunks = sum(r.get('chunks_count', 0) for r in results)

        logger.info("\n" + "=" * 80)
        logger.info("å‡¦ç†å®Œäº†")
        logger.info(f"  æˆåŠŸ: {success_count}/{len(results)}")
        logger.info(f"  å¤±æ•—: {failed_count}/{len(results)}")
        logger.info(f"  æŠ½å‡ºå•†å“æ•°: {total_products}ä»¶")
        logger.info(f"  ç”Ÿæˆãƒãƒ£ãƒ³ã‚¯æ•°: {total_chunks}å€‹")
        logger.info("=" * 80)

        return {
            'total': len(results),
            'success': success_count,
            'failed': failed_count,
            'total_products': total_products,
            'total_chunks': total_chunks,
            'results': results
        }


async def main():
    """ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®ãƒ‘ãƒ¼ã‚¹
    dry_run = '--dry-run' in sys.argv
    limit = 10
    store_name = None

    for arg in sys.argv:
        if arg.startswith('--limit='):
            try:
                limit = int(arg.split('=')[1])
            except:
                pass
        elif arg.startswith('--store='):
            store_name = arg.split('=')[1]

    processor = FlyerProcessor()

    if dry_run:
        logger.info("ğŸ” DRY RUN ãƒ¢ãƒ¼ãƒ‰: å®Ÿéš›ã®å‡¦ç†ã¯è¡Œã„ã¾ã›ã‚“")
        pending = processor.get_pending_flyers(limit, store_name)
        logger.info(f"å‡¦ç†å¯¾è±¡: {len(pending)}ä»¶")
        for flyer in pending:
            logger.info(f"  - {flyer.get('organization')}: {flyer.get('file_name')}")
        return

    result = await processor.process_pending_flyers(limit, store_name)

    # çµæœã‚’è¡¨ç¤º
    print("\n" + "=" * 80)
    print("ğŸ›’ ãƒãƒ©ã‚·å‡¦ç†çµæœ")
    print("=" * 80)
    print(f"å‡¦ç†ä»¶æ•°: {result['total']}")
    print(f"æˆåŠŸ: {result['success']}")
    print(f"å¤±æ•—: {result['failed']}")
    print(f"æŠ½å‡ºå•†å“æ•°: {result['total_products']}")
    print(f"ç”Ÿæˆãƒãƒ£ãƒ³ã‚¯æ•°: {result['total_chunks']}")
    print("=" * 80)


if __name__ == "__main__":
    asyncio.run(main())
