"""
æ±æ€¥ã‚¹ãƒˆã‚¢ãƒãƒƒãƒˆã‚¹ãƒ¼ãƒ‘ãƒ¼ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç®¡ç†å¯¾å¿œç‰ˆ

ã‚«ãƒ†ã‚´ãƒªãƒ¼ã”ã¨ã®å®Ÿè¡Œã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ç®¡ç†ã—ã€
ã‚µãƒ¼ãƒãƒ¼è² è·ã‚’æœ€å°é™ã«æŠ‘ãˆã‚‹å¾…æ©Ÿæ™‚é–“ã‚’å®Ÿè£…ã—ã¾ã™ã€‚
"""

import os
import sys
import asyncio
import random
import logging
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
root_dir = Path(__file__).parent.parent.parent
sys.path.insert(0, str(root_dir))

from dotenv import load_dotenv
load_dotenv(root_dir / ".env")

from B_ingestion.common.category_manager import CategoryManager
from B_ingestion.tokyu_store.product_ingestion import TokyuStoreProductIngestionPipeline

# ãƒ­ã‚¬ãƒ¼è¨­å®š
logger = logging.getLogger(__name__)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)


class PoliteTokyuStorePipeline:
    """ã‚µãƒ¼ãƒãƒ¼è² è·ã«é…æ…®ã—ãŸã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç®¡ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""

    def __init__(
        self,
        login_id: str,
        password: str,
        zip_code: str = "158-0094",
        headless: bool = True,
        dry_run: bool = False
    ):
        """
        Args:
            login_id: æ±æ€¥ã‚¹ãƒˆã‚¢ãƒ­ã‚°ã‚¤ãƒ³ID
            password: ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰
            zip_code: é…é”ã‚¨ãƒªã‚¢éƒµä¾¿ç•ªå·
            headless: ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰
            dry_run: Dry Run ãƒ¢ãƒ¼ãƒ‰ï¼ˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®åˆæœŸåŒ–ã®ã¿ï¼‰
        """
        self.pipeline = TokyuStoreProductIngestionPipeline(
            login_id=login_id,
            password=password,
            zip_code=zip_code,
            headless=headless
        )
        self.manager = CategoryManager()
        self.dry_run = dry_run
        self.store_name = "tokyu_store"

    async def polite_wait_between_pages(self):
        """ãƒšãƒ¼ã‚¸é·ç§»é–“ã®å¾…æ©Ÿï¼ˆ4ç§’ã€œ8ç§’ã®ãƒ©ãƒ³ãƒ€ãƒ ï¼‰"""
        wait_time = random.uniform(4.0, 8.0)
        logger.info(f"â³ ãƒšãƒ¼ã‚¸é·ç§»å¾…æ©Ÿ: {wait_time:.1f}ç§’")
        await asyncio.sleep(wait_time)

    async def polite_wait_between_categories(self):
        """ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ‡æ›¿æ™‚ã®å¾…æ©Ÿï¼ˆ15ç§’ã€œ30ç§’ã®ãƒ©ãƒ³ãƒ€ãƒ ï¼‰"""
        wait_time = random.uniform(15.0, 30.0)
        logger.info(f"â³ ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ‡æ›¿å¾…æ©Ÿ: {wait_time:.1f}ç§’")
        await asyncio.sleep(wait_time)

    async def initialize_categories(self):
        """ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’åˆæœŸåŒ–ï¼ˆåˆå›å®Ÿè¡Œæ™‚ï¼‰"""
        logger.info("ğŸ“‹ ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’åˆæœŸåŒ–ã—ã¾ã™...")

        # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼èµ·å‹•
        success = await self.pipeline.start()
        if not success:
            logger.error("âŒ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼èµ·å‹•å¤±æ•—")
            return False

        try:
            # ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’å‹•çš„ã«å–å¾—
            categories = await self.pipeline.discover_categories()

            if not categories:
                logger.warning("ã‚«ãƒ†ã‚´ãƒªãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                return False

            # CategoryManagerã«ç™»éŒ²
            category_list = [
                {"name": cat["name"], "url": cat["url"]}
                for cat in categories
            ]

            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§åˆæœŸåŒ–
            # é–‹å§‹æ—¥: æ˜æ—¥ã€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒ«: 7æ—¥
            tomorrow = datetime.now().strftime("%Y-%m-%d")
            self.manager.initialize_store_categories(
                self.store_name,
                category_list,
                default_interval_days=7,
                default_start_date=tomorrow
            )

            logger.info(f"âœ… {len(categories)}ä»¶ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
            logger.info("ç®¡ç†ç”»é¢ã§è¨­å®šã‚’èª¿æ•´ã—ã¦ãã ã•ã„:")
            logger.info("  streamlit run B_ingestion/netsuper_category_manager_ui.py")

            return True

        finally:
            await self.pipeline.close()

    async def run_scheduled_categories(self):
        """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã«åŸºã¥ã„ã¦ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’å‡¦ç†"""
        logger.info("="*80)
        logger.info("æ±æ€¥ã‚¹ãƒˆã‚¢ãƒãƒƒãƒˆã‚¹ãƒ¼ãƒ‘ãƒ¼ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿè¡Œé–‹å§‹")
        logger.info("="*80)

        # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼èµ·å‹•
        success = await self.pipeline.start()
        if not success:
            logger.error("âŒ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼èµ·å‹•å¤±æ•—")
            return

        try:
            # è¨­å®šã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’å–å¾—
            categories = self.manager.get_all_categories(self.store_name)

            if not categories:
                logger.warning("ã‚«ãƒ†ã‚´ãƒªãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚åˆå›å®Ÿè¡Œã—ã¦ãã ã•ã„:")
                logger.warning("  python -m B_ingestion.tokyu_store.process_with_schedule --init")
                return

            # ä»Šæ—¥å®Ÿè¡Œã™ã¹ãã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            today = datetime.now()
            runnable_categories = []

            for cat in categories:
                if self.manager.should_run_category(self.store_name, cat["name"], today):
                    runnable_categories.append(cat)

            logger.info(f"ğŸ“Š ç·ã‚«ãƒ†ã‚´ãƒªãƒ¼æ•°: {len(categories)}ä»¶")
            logger.info(f"âœ… æœ¬æ—¥å®Ÿè¡Œå¯¾è±¡: {len(runnable_categories)}ä»¶")

            if not runnable_categories:
                logger.info("æœ¬æ—¥å®Ÿè¡Œã™ã‚‹ã‚«ãƒ†ã‚´ãƒªãƒ¼ã¯ã‚ã‚Šã¾ã›ã‚“")
                return

            # ã‚«ãƒ†ã‚´ãƒªãƒ¼ã”ã¨ã«å‡¦ç†
            for idx, cat in enumerate(runnable_categories, 1):
                logger.info("")
                logger.info("="*80)
                logger.info(f"ğŸ“¦ ã‚«ãƒ†ã‚´ãƒªãƒ¼ {idx}/{len(runnable_categories)}: {cat['name']}")
                logger.info(f"   URL: {cat['url']}")
                logger.info("="*80)

                try:
                    # ã‚«ãƒ†ã‚´ãƒªãƒ¼ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹
                    await self.pipeline.scraper.page.goto(cat['url'], wait_until="domcontentloaded")
                    await self.polite_wait_between_pages()

                    # ã“ã“ã§å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹å‡¦ç†ã‚’å®Ÿè£…
                    # ï¼ˆæ—¢å­˜ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ­ã‚¸ãƒƒã‚¯ã‚’å‘¼ã³å‡ºã™ï¼‰
                    # products = await self.pipeline.scrape_category_products(cat['url'])
                    # await self.pipeline.save_products(products)

                    logger.info(f"âœ… ã‚«ãƒ†ã‚´ãƒªãƒ¼ {cat['name']} ã®å‡¦ç†å®Œäº†")

                    # å®Ÿè¡Œæ¸ˆã¿ã¨ã—ã¦ãƒãƒ¼ã‚¯
                    self.manager.mark_as_run(self.store_name, cat["name"], today)

                    # ã‚«ãƒ†ã‚´ãƒªãƒ¼é–“ã®å¾…æ©Ÿ
                    if idx < len(runnable_categories):
                        await self.polite_wait_between_categories()

                except Exception as e:
                    logger.error(f"âŒ ã‚«ãƒ†ã‚´ãƒªãƒ¼ {cat['name']} å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
                    # ã‚¨ãƒ©ãƒ¼æ™‚ã¯é•·ã‚ã«å¾…æ©Ÿ
                    await asyncio.sleep(60)
                    continue

            logger.info("")
            logger.info("="*80)
            logger.info("âœ… ã™ã¹ã¦ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼å‡¦ç†å®Œäº†")
            logger.info("="*80)

        finally:
            await self.pipeline.close()


async def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    import argparse

    parser = argparse.ArgumentParser(description="æ±æ€¥ã‚¹ãƒˆã‚¢ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ï¼ˆã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç®¡ç†å¯¾å¿œï¼‰")
    parser.add_argument("--init", action="store_true", help="ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’åˆæœŸåŒ–ï¼ˆåˆå›å®Ÿè¡Œæ™‚ã®ã¿ï¼‰")
    parser.add_argument("--headless", action="store_true", default=True, help="ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰")
    parser.add_argument("--zip-code", default="158-0094", help="é…é”ã‚¨ãƒªã‚¢éƒµä¾¿ç•ªå·")
    args = parser.parse_args()

    login_id = os.getenv("TOKYU_STORE_LOGIN_ID")
    password = os.getenv("TOKYU_STORE_PASSWORD")

    if not login_id or not password:
        logger.error("âŒ ç’°å¢ƒå¤‰æ•° TOKYU_STORE_LOGIN_ID ã¨ TOKYU_STORE_PASSWORD ã‚’è¨­å®šã—ã¦ãã ã•ã„")
        return

    pipeline = PoliteTokyuStorePipeline(
        login_id=login_id,
        password=password,
        zip_code=args.zip_code,
        headless=args.headless
    )

    if args.init:
        # åˆæœŸåŒ–ãƒ¢ãƒ¼ãƒ‰
        await pipeline.initialize_categories()
    else:
        # é€šå¸¸å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰
        await pipeline.run_scheduled_categories()


if __name__ == "__main__":
    asyncio.run(main())
