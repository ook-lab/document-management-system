"""
å…±é€šå•†å“å–ã‚Šè¾¼ã¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åŸºç›¤ã‚¯ãƒ©ã‚¹
å…¨ãƒãƒƒãƒˆã‚¹ãƒ¼ãƒ‘ãƒ¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§å…±æœ‰ã™ã‚‹å‡¦ç†ã‚’å®šç¾©
"""

from abc import ABC, abstractmethod
from datetime import date, datetime
from typing import Dict, List, Optional, Set
from uuid import UUID
import uuid
import os

from A_common.database.client import DatabaseClient
from C_ai_common.llm_client.llm_client import LLMClient
from loguru import logger
from openai import OpenAI


class BaseProductIngestionPipeline(ABC):
    """å•†å“å–ã‚Šè¾¼ã¿ã®å…±é€šåŸºç›¤ã‚¯ãƒ©ã‚¹"""

    def __init__(self, organization_name: str, headless: bool = True):
        """
        åˆæœŸåŒ–

        Args:
            organization_name: çµ„ç¹”åï¼ˆæ±æ€¥ã‚¹ãƒˆã‚¢ã€æ¥½å¤©è¥¿å‹ã€ãƒ€ã‚¤ã‚¨ãƒ¼ï¼‰
            headless: ãƒ–ãƒ©ã‚¦ã‚¶ã®ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰
        """
        self.organization_name = organization_name
        self.headless = headless
        self.db = DatabaseClient(use_service_role=True)
        self.llm_client = LLMClient()
        self.scraper = None

        # OpenAI clientã®åˆæœŸåŒ–ï¼ˆembeddingç”Ÿæˆç”¨ï¼‰
        openai_api_key = os.getenv("OPENAI_API_KEY")
        if openai_api_key:
            self.openai_client = OpenAI(api_key=openai_api_key)
            self.embedding_enabled = True
            logger.info("OpenAI Embeddingæ©Ÿèƒ½ãŒæœ‰åŠ¹åŒ–ã•ã‚Œã¾ã—ãŸ")
        else:
            self.openai_client = None
            self.embedding_enabled = False
            logger.warning("OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚Embeddingç”Ÿæˆã¯ç„¡åŠ¹ã§ã™")

    @abstractmethod
    async def start(self) -> bool:
        """
        ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã®èµ·å‹•ã¨ãƒ­ã‚°ã‚¤ãƒ³
        å„ã‚¹ãƒˆã‚¢å›ºæœ‰ã®å®Ÿè£…ãŒå¿…è¦
        """
        pass

    @abstractmethod
    async def close(self):
        """ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        pass

    async def check_existing_products(self, jan_codes: List[str]) -> Set[str]:
        """
        æ—¢å­˜å•†å“ã®ãƒã‚§ãƒƒã‚¯ï¼ˆJANã‚³ãƒ¼ãƒ‰ã§é‡è¤‡æ’é™¤ï¼‰

        Args:
            jan_codes: ãƒã‚§ãƒƒã‚¯ã™ã‚‹JANã‚³ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ

        Returns:
            æ—¢å­˜ã®JANã‚³ãƒ¼ãƒ‰ã®ã‚»ãƒƒãƒˆ
        """
        if not jan_codes:
            return set()

        # ç©ºæ–‡å­—ãƒ»Noneã‚’é™¤å¤–
        valid_jan_codes = [code for code in jan_codes if code]

        if not valid_jan_codes:
            return set()

        result = self.db.client.table('Rawdata_NETSUPER_items').select(
            'jan_code'
        ).in_('jan_code', valid_jan_codes).execute()

        return {row['jan_code'] for row in result.data if row.get('jan_code')}

    async def check_existing_products_by_name(self, products: List[Dict]) -> Dict[tuple, str]:
        """
        æ—¢å­˜å•†å“ã®ãƒã‚§ãƒƒã‚¯ï¼ˆå•†å“å+çµ„ç¹”ã§é‡è¤‡æ’é™¤ï¼‰
        JANã‚³ãƒ¼ãƒ‰ãŒãªã„å•†å“ç”¨

        Args:
            products: å•†å“ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆï¼ˆproduct_nameã¨jan_codeã‚’å«ã‚€ï¼‰

        Returns:
            (product_name, organization) -> product_id ã®ãƒãƒƒãƒ”ãƒ³ã‚°
        """
        # JANã‚³ãƒ¼ãƒ‰ãŒãªã„å•†å“ã®ã¿ã‚’æŠ½å‡º
        no_jan_products = [p for p in products if not p.get('jan_code')]

        if not no_jan_products:
            return {}

        # å•†å“åã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ
        product_names = list(set([p.get('product_name') for p in no_jan_products if p.get('product_name')]))

        if not product_names:
            return {}

        # è©²å½“ã™ã‚‹å•†å“åã¨çµ„ç¹”ã®çµ„ã¿åˆã‚ã›ã§æ—¢å­˜ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’æ¤œç´¢
        result = self.db.client.table('Rawdata_NETSUPER_items').select(
            'id, product_name, organization'
        ).in_('product_name', product_names).eq(
            'organization', self.organization_name
        ).is_('jan_code', 'null').execute()

        # (product_name, organization) -> id ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½œæˆ
        existing_map = {}
        for row in result.data:
            key = (row['product_name'], row['organization'])
            existing_map[key] = row['id']

        return existing_map

    def _generate_embedding(self, text: str) -> Optional[List[float]]:
        """
        å•†å“åã‹ã‚‰embeddingã‚’ç”Ÿæˆ

        Args:
            text: å•†å“å

        Returns:
            1536æ¬¡å…ƒã®ãƒ™ã‚¯ãƒˆãƒ«ï¼ˆå¤±æ•—æ™‚ã¯Noneï¼‰
        """
        if not self.embedding_enabled or not self.openai_client:
            return None

        if not text:
            return None

        try:
            response = self.openai_client.embeddings.create(
                model="text-embedding-3-small",
                input=text
            )
            return response.data[0].embedding
        except Exception as e:
            logger.error(f"Embeddingç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def _prepare_product_data(
        self,
        product: Dict,
        category_name: Optional[str] = None,
        general_name: Optional[str] = None,
        category_id: Optional[UUID] = None,
        confidence: Optional[float] = None
    ) -> Dict:
        """
        å•†å“ãƒ‡ãƒ¼ã‚¿ã®æ­£è¦åŒ–ã¨æº–å‚™

        Args:
            product: ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã‹ã‚‰å–å¾—ã—ãŸç”Ÿãƒ‡ãƒ¼ã‚¿
            category_name: ã‚«ãƒ†ã‚´ãƒªåï¼ˆã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼å–å¾—å€¤ï¼‰
            general_name: ä¸€èˆ¬åè©ï¼ˆåˆ†é¡æ¸ˆã¿ã®å ´åˆï¼‰
            category_id: ã‚«ãƒ†ã‚´ãƒªIDï¼ˆåˆ†é¡æ¸ˆã¿ã®å ´åˆï¼‰
            confidence: åˆ†é¡ä¿¡é ¼åº¦

        Returns:
            ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æŒ¿å…¥ç”¨ã®æ­£è¦åŒ–æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿
        """
        today = date.today()

        # å•†å“åã‚’å–å¾—ï¼ˆã‚µã‚¤ãƒˆè¡¨è¨˜ã®ã¾ã¾ä¿å­˜ï¼‰
        product_name = product.get("product_name", "")

        # ä¾¡æ ¼ã®ãƒ‘ãƒ¼ã‚¹ï¼ˆæœ¬ä½“ä¾¡æ ¼ã¨ç¨è¾¼ä¾¡æ ¼ã®ä¸¡æ–¹ï¼‰
        # æœ¬ä½“ä¾¡æ ¼ï¼ˆç¨æŠœï¼‰
        price = product.get("price")
        current_price = None
        if price is not None:
            try:
                if isinstance(price, (int, float)):
                    current_price = float(price)
                else:
                    current_price = float(str(price).replace(",", "").replace("å††", "").replace("Â¥", "").strip())
            except (ValueError, AttributeError):
                current_price = None

        # ç¨è¾¼ä¾¡æ ¼
        price_tax_included = product.get("price_tax_included")
        current_price_tax_included = None
        if price_tax_included is not None:
            try:
                if isinstance(price_tax_included, (int, float)):
                    current_price_tax_included = float(price_tax_included)
                else:
                    current_price_tax_included = float(str(price_tax_included).replace(",", "").replace("å††", "").replace("Â¥", "").strip())
            except (ValueError, AttributeError):
                current_price_tax_included = None

        # price_text: å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã‚’ä¿æŒï¼ˆæœ¬ä½“ä¾¡æ ¼ / ç¨è¾¼ä¾¡æ ¼ï¼‰
        price_text_parts = []
        if price is not None:
            price_text_parts.append(f"æœ¬ä½“Â¥{price}")
        if price_tax_included is not None:
            price_text_parts.append(f"ç¨è¾¼Â¥{price_tax_included}")
        price_text = " / ".join(price_text_parts) if price_text_parts else ""

        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        metadata = {
            "raw_data": product,
            "scraping_timestamp": datetime.now().isoformat()
        }

        # ãƒ‡ãƒ¼ã‚¿æ§‹ç¯‰
        data = {
            # åŸºæœ¬æƒ…å ±
            "source_type": "online_supermarket",
            "workspace": "shopping",
            "doc_type": "online_grocery_item",
            "organization": self.organization_name,

            # å•†å“æƒ…å ±
            "product_name": product_name,
            "jan_code": product.get("jan_code"),

            # ä¾¡æ ¼æƒ…å ±
            "current_price": current_price,
            "current_price_tax_included": current_price_tax_included,
            "price_text": price_text,

            # åˆ†é¡æƒ…å ±
            "category": category_name,
            "general_name": general_name,
            "category_id": str(category_id) if category_id else None,
            "classification_confidence": confidence,
            "needs_approval": general_name is None,  # æœªåˆ†é¡ã®å ´åˆã¯æ‰¿èªå¾…ã¡

            # ãã®ä»–
            "manufacturer": product.get("manufacturer"),
            "image_url": product.get("image_url"),
            "in_stock": product.get("in_stock", True),
            "is_available": product.get("is_available", True),

            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            "metadata": metadata,
            "document_date": today.isoformat(),
            "last_scraped_at": datetime.now().isoformat(),
            "updated_at": datetime.now().isoformat()
        }

        # Embeddingã‚’ç”Ÿæˆï¼ˆè¤‡æ•°ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‹ã‚‰ï¼‰
        # product_name + general_name + category + manufacturer ã‚’çµ„ã¿åˆã‚ã›ã‚‹
        text_parts = [
            product_name,
            general_name or '',
            category_name or '',
            product.get("manufacturer") or ''
        ]
        text_for_embedding = ' '.join(filter(None, text_parts)).strip()

        embedding = self._generate_embedding(text_for_embedding)
        if embedding:
            # vectorå‹ã¨ã—ã¦ä¿å­˜ã™ã‚‹ãŸã‚ã«æ–‡å­—åˆ—å½¢å¼ã«å¤‰æ›
            embedding_str = '[' + ','.join(map(str, embedding)) + ']'
            data["embedding"] = embedding_str
            logger.debug(f"Embeddingç”ŸæˆæˆåŠŸ: {text_for_embedding[:50]}...")

        return data

    async def process_category_page(
        self,
        category_url: str,
        page: int = 1,
        category_name: Optional[str] = None
    ) -> Dict:
        """
        ã‚«ãƒ†ã‚´ãƒªãƒšãƒ¼ã‚¸ã®å‡¦ç†ï¼ˆå…±é€šãƒ­ã‚¸ãƒƒã‚¯ï¼‰

        Args:
            category_url: ã‚«ãƒ†ã‚´ãƒªURL
            page: ãƒšãƒ¼ã‚¸ç•ªå·
            category_name: ã‚«ãƒ†ã‚´ãƒªå

        Returns:
            å‡¦ç†çµæœ
        """
        if not self.scraper:
            raise RuntimeError("Scraper not initialized. Call start() first.")

        logger.info(f"ãƒšãƒ¼ã‚¸ {page} ã‚’å‡¦ç†ä¸­...")

        # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼å›ºæœ‰ã®å®Ÿè£…ã‚’å‘¼ã³å‡ºã—ï¼ˆã‚¿ãƒ—ãƒ«è¿”å´ï¼‰
        products, pagination_info = await self.scraper.fetch_products_page(category_url, page)

        # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›
        if page == 1 and pagination_info:
            logger.info(f"ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±: {pagination_info}")

        if not products:
            logger.warning("å•†å“ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return {
                "success": True,
                "total_products": 0,
                "new_products": 0,
                "updated_products": 0,
                "pagination_info": pagination_info
            }

        # å•†å“ãƒ‡ãƒ¼ã‚¿ã®æ­£è¦åŒ–ã¨ä¿å­˜
        jan_codes = [p.get("jan_code") for p in products if p.get("jan_code")]
        existing_jan_codes = await self.check_existing_products(jan_codes)

        # JANã‚³ãƒ¼ãƒ‰ãŒãªã„å•†å“ã®æ—¢å­˜ãƒã‚§ãƒƒã‚¯ï¼ˆå•†å“å+çµ„ç¹”ï¼‰
        existing_by_name = await self.check_existing_products_by_name(products)

        insert_count = 0
        update_count = 0

        for product in products:
            # å•†å“ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆåˆ†é¡ã¯å¾Œã§å®Ÿæ–½ï¼‰
            product_data = self._prepare_product_data(product, category_name)
            jan_code = product.get("jan_code")
            product_name = product.get("product_name")

            try:
                if jan_code and jan_code in existing_jan_codes:
                    # JANã‚³ãƒ¼ãƒ‰ã§æ—¢å­˜å•†å“ã‚’æ›´æ–°
                    # general_name ã¨ keywords ã¯é™¤å¤–ï¼ˆAIç”Ÿæˆæ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒï¼‰
                    update_data = {k: v for k, v in product_data.items() if k not in ['general_name', 'keywords']}
                    self.db.client.table('Rawdata_NETSUPER_items').update(
                        update_data
                    ).eq('jan_code', jan_code).execute()
                    update_count += 1
                elif not jan_code and (product_name, self.organization_name) in existing_by_name:
                    # JANã‚³ãƒ¼ãƒ‰ãªã—å•†å“ã‚’å•†å“å+çµ„ç¹”ã§æ›´æ–°
                    # general_name ã¨ keywords ã¯é™¤å¤–ï¼ˆAIç”Ÿæˆæ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒï¼‰
                    existing_id = existing_by_name[(product_name, self.organization_name)]
                    update_data = {k: v for k, v in product_data.items() if k not in ['general_name', 'keywords']}
                    self.db.client.table('Rawdata_NETSUPER_items').update(
                        update_data
                    ).eq('id', existing_id).execute()
                    update_count += 1
                else:
                    # æ–°è¦å•†å“ã‚’æŒ¿å…¥
                    product_data["created_at"] = datetime.now().isoformat()
                    self.db.client.table('Rawdata_NETSUPER_items').insert(
                        product_data
                    ).execute()
                    insert_count += 1

            except Exception as e:
                logger.error(f"Failed to save product {product_name}: {e}")

        logger.info(f"âœ… å‡¦ç†å®Œäº†: åˆè¨ˆ{len(products)}ä»¶ï¼ˆæ–°è¦{insert_count}ä»¶ã€æ›´æ–°{update_count}ä»¶ï¼‰")

        return {
            "success": True,
            "total_products": len(products),
            "new_products": insert_count,
            "updated_products": update_count,
            "pagination_info": pagination_info
        }

    async def process_category_all_pages(
        self,
        category_url: str,
        category_name: Optional[str] = None,
        max_pages: int = 100
    ) -> Dict:
        """
        ã‚«ãƒ†ã‚´ãƒªã®å…¨ãƒšãƒ¼ã‚¸ã‚’å‡¦ç†

        Args:
            category_url: ã‚«ãƒ†ã‚´ãƒªURL
            category_name: ã‚«ãƒ†ã‚´ãƒªå
            max_pages: æœ€å¤§ãƒšãƒ¼ã‚¸æ•°

        Returns:
            å‡¦ç†çµæœ
        """
        logger.info(f"ã‚«ãƒ†ã‚´ãƒªãƒ¼ '{category_name}' ã®å…¨ãƒšãƒ¼ã‚¸å‡¦ç†é–‹å§‹")

        page = 1
        total_products = 0
        total_new = 0
        total_updated = 0
        total_pages_from_pagination = None

        while page <= max_pages:
            result = await self.process_category_page(category_url, page, category_name)

            # åˆå›ã®ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±ã‚’å–å¾—
            if page == 1 and result.get("pagination_info"):
                pagination = result["pagination_info"]
                total_pages_from_pagination = pagination.get("totalPages")
                if total_pages_from_pagination:
                    logger.info(f"ğŸ“„ æ¤œå‡ºã•ã‚ŒãŸç·ãƒšãƒ¼ã‚¸æ•°: {total_pages_from_pagination}")
                    # ç·ãƒšãƒ¼ã‚¸æ•°ãŒmax_pagesã‚ˆã‚Šå°‘ãªã„å ´åˆã€max_pagesã‚’æ›´æ–°
                    if total_pages_from_pagination < max_pages:
                        max_pages = total_pages_from_pagination
                        logger.info(f"âœ… å‡¦ç†ãƒšãƒ¼ã‚¸æ•°ã‚’ {total_pages_from_pagination} ã«åˆ¶é™")

            if not result.get("success") or result.get("total_products", 0) == 0:
                logger.info(f"ãƒšãƒ¼ã‚¸ {page} ã§å•†å“ãªã—ã€ã‚«ãƒ†ã‚´ãƒªãƒ¼å‡¦ç†çµ‚äº†")
                break

            total_products += result.get("total_products", 0)
            total_new += result.get("new_products", 0)
            total_updated += result.get("updated_products", 0)

            # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±ã«åŸºã¥ãçµ‚äº†åˆ¤å®š
            if total_pages_from_pagination and page >= total_pages_from_pagination:
                logger.info(f"âœ… å…¨{total_pages_from_pagination}ãƒšãƒ¼ã‚¸ã®å‡¦ç†å®Œäº†")
                break

            page += 1

        logger.info(f"âœ… ã‚«ãƒ†ã‚´ãƒªãƒ¼ '{category_name}' å®Œäº†")
        logger.info(f"   åˆè¨ˆ: {total_products}ä»¶ï¼ˆæ–°è¦{total_new}ä»¶ã€æ›´æ–°{total_updated}ä»¶ï¼‰")

        return {
            "success": True,
            "category_url": category_url,
            "category_name": category_name,
            "total_products": total_products,
            "new_products": total_new,
            "updated_products": total_updated,
            "pages_processed": page - 1,
            "total_pages": total_pages_from_pagination
        }
