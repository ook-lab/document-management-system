"""
è¤‡åˆä¿¡é ¼åº¦è¨ˆç®—ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« (Confidence Calculator)

ç›®çš„: AIã®ç¢ºä¿¡åº¦ã«åŠ ãˆã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°ã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å……è¶³ç‡ã€
     ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã‚’çµ„ã¿åˆã‚ã›ãŸç·åˆçš„ãªå“è³ªã‚¹ã‚³ã‚¢ (total_confidence) ã‚’ç®—å‡º

è¨­è¨ˆ: Phase 2 (Track 1) - è¤‡åˆæŒ‡æ¨™ã«ã‚ˆã‚‹Confidenceè¨ˆç®—
     AUTO_INBOX_COMPLETE_v3.0.md ã®ã€Œ2.1.1 è¤‡åˆæŒ‡æ¨™ã«ã‚ˆã‚‹Confidenceè¨ˆç®—ã€ã«æº–æ‹ 

åŠ é‡å¹³å‡å¼:
    total_confidence = (model_confidence * 0.4) +
                      (keyword_match_score * 0.3) +
                      (metadata_completeness * 0.2) +
                      (data_consistency * 0.1)
"""

import re
from typing import Dict, Any, List, Optional
from loguru import logger


# æ–‡æ›¸ã‚¿ã‚¤ãƒ—åˆ¥ã®å¿…é ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å®šç¾©
REQUIRED_KEYWORDS = {
    'timetable': ['æ™‚é–“å‰²', 'æ™‚é™', 'æ›œæ—¥', 'æˆæ¥­', 'ã‚¯ãƒ©ã‚¹', 'å­¦å¹´'],
    'notice': ['ãŠçŸ¥ã‚‰ã›', 'é€šçŸ¥', 'é€£çµ¡', 'ä¿è­·è€…', 'å­¦æ ¡'],
    'homework': ['å®¿é¡Œ', 'èª²é¡Œ', 'æå‡º', 'æœŸé™'],
    'test_exam': ['è©¦é¨“', 'ãƒ†ã‚¹ãƒˆ', 'ç¯„å›²', 'æ—¥ç¨‹', 'ç‚¹æ•°'],
    'report_card': ['é€šçŸ¥è¡¨', 'æˆç¸¾', 'è©•ä¾¡', 'æ‰€è¦‹'],
    'invoice': ['è«‹æ±‚æ›¸', 'é‡‘é¡', 'åˆè¨ˆ', 'æ”¯æ‰•'],
    'contract': ['å¥‘ç´„', 'å¥‘ç´„æ›¸', 'å¥‘ç´„è€…', 'æœŸé–“'],
    'meeting_minutes': ['è­°äº‹éŒ²', 'ä¼šè­°', 'å‡ºå¸­è€…', 'è­°é¡Œ'],
    'receipt': ['é ˜åæ›¸', 'ãƒ¬ã‚·ãƒ¼ãƒˆ', 'é‡‘é¡', 'æ—¥ä»˜'],
}

# æ–‡æ›¸ã‚¿ã‚¤ãƒ—åˆ¥ã®å¿…é ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
REQUIRED_METADATA_FIELDS = {
    'timetable': ['grade', 'period'],
    'notice': ['title', 'date', 'from'],
    'homework': ['subject', 'due_date', 'description'],
    'test_exam': ['subject', 'date', 'scope'],
    'report_card': ['student_name', 'grade', 'semester'],
    'invoice': ['amount', 'due_date', 'invoice_number'],
    'contract': ['party_a', 'party_b', 'start_date', 'end_date'],
    'meeting_minutes': ['meeting_date', 'attendees', 'agenda'],
    'receipt': ['amount', 'date', 'store_name'],
}


def calculate_keyword_match_score(text: str, doc_type: str) -> float:
    """
    ãƒ†ã‚­ã‚¹ãƒˆã¨æ–‡æ›¸ã‚¿ã‚¤ãƒ—ã«åŸºã¥ãã€å¿…é ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ä¸€è‡´åº¦ã‚’è¨ˆç®—

    Args:
        text: æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
        doc_type: æ–‡æ›¸ã‚¿ã‚¤ãƒ—

    Returns:
        ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä¸€è‡´ã‚¹ã‚³ã‚¢ (0.0 ~ 1.0)
    """
    if not text or not doc_type:
        return 0.0

    # doc_typeã«å¯¾å¿œã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆã‚’å–å¾—
    required_keywords = REQUIRED_KEYWORDS.get(doc_type, [])

    if not required_keywords:
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å®šç¾©ãŒãªã„å ´åˆã¯ä¸­ç«‹ã‚¹ã‚³ã‚¢
        logger.debug(f"doc_type '{doc_type}' ã«ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å®šç¾©ãŒã‚ã‚Šã¾ã›ã‚“")
        return 0.5

    # ãƒ†ã‚­ã‚¹ãƒˆã‚’æ­£è¦åŒ–ï¼ˆå°æ–‡å­—åŒ–ã€ç©ºç™½é™¤å»ï¼‰
    normalized_text = text.lower()

    # ä¸€è‡´ã—ãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
    matched_count = 0
    for keyword in required_keywords:
        if keyword.lower() in normalized_text:
            matched_count += 1

    # ä¸€è‡´ç‡ã‚’è¨ˆç®—
    match_ratio = matched_count / len(required_keywords)

    logger.debug(f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒ: {matched_count}/{len(required_keywords)} = {match_ratio:.2f}")

    return match_ratio


def calculate_metadata_completeness(metadata: Dict[str, Any], doc_type: str) -> float:
    """
    æŠ½å‡ºã•ã‚ŒãŸãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒã€æ–‡æ›¸ã‚¿ã‚¤ãƒ—ã”ã¨ã®å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ã©ã‚Œã ã‘æº€ãŸã—ã¦ã„ã‚‹ã‹ã‚’è¨ˆç®—

    Args:
        metadata: æŠ½å‡ºã•ã‚ŒãŸãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        doc_type: æ–‡æ›¸ã‚¿ã‚¤ãƒ—

    Returns:
        ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å……è¶³ç‡ (0.0 ~ 1.0)
    """
    if not metadata or not doc_type:
        return 0.0

    # doc_typeã«å¯¾å¿œã™ã‚‹å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒªã‚¹ãƒˆã‚’å–å¾—
    required_fields = REQUIRED_METADATA_FIELDS.get(doc_type, [])

    if not required_fields:
        # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å®šç¾©ãŒãªã„å ´åˆã¯ä¸­ç«‹ã‚¹ã‚³ã‚¢
        logger.debug(f"doc_type '{doc_type}' ã«å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å®šç¾©ãŒã‚ã‚Šã¾ã›ã‚“")
        return 0.5

    # å­˜åœ¨ã™ã‚‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
    present_count = 0
    for field in required_fields:
        value = metadata.get(field)

        # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒå­˜åœ¨ã—ã€ã‹ã¤ç©ºã§ãªã„å ´åˆ
        if value is not None and value != "" and value != []:
            present_count += 1

    # å……è¶³ç‡ã‚’è¨ˆç®—
    completeness_ratio = present_count / len(required_fields)

    logger.debug(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å……è¶³ç‡: {present_count}/{len(required_fields)} = {completeness_ratio:.2f}")

    return completeness_ratio


def calculate_data_consistency(metadata: Dict[str, Any], doc_type: str) -> float:
    """
    ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ã‚’ãƒã‚§ãƒƒã‚¯

    Args:
        metadata: æŠ½å‡ºã•ã‚ŒãŸãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        doc_type: æ–‡æ›¸ã‚¿ã‚¤ãƒ—

    Returns:
        ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã‚¹ã‚³ã‚¢ (0.0 ~ 1.0)
    """
    if not metadata:
        return 0.0

    consistency_score = 1.0
    issues = []

    # æ—¥ä»˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
    date_fields = ['date', 'due_date', 'start_date', 'end_date', 'meeting_date', 'document_date']
    for field in date_fields:
        if field in metadata:
            date_value = metadata[field]
            if isinstance(date_value, str) and date_value:
                # æ—¥ä»˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ç°¡æ˜“ãƒã‚§ãƒƒã‚¯ (YYYY-MM-DD, YYYY/MM/DD, YYYYå¹´MMæœˆDDæ—¥)
                date_patterns = [
                    r'\d{4}[-/]\d{1,2}[-/]\d{1,2}',  # YYYY-MM-DD or YYYY/MM/DD
                    r'\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥',   # YYYYå¹´MMæœˆDDæ—¥
                ]
                if not any(re.search(pattern, date_value) for pattern in date_patterns):
                    issues.append(f"{field}ã®æ—¥ä»˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒä¸æ­£: {date_value}")
                    consistency_score -= 0.2

    # æ•°å€¤ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
    numeric_fields = ['amount', 'score', 'grade_number']
    for field in numeric_fields:
        if field in metadata:
            value = metadata[field]
            if isinstance(value, str):
                # æ•°å€¤ã‚’å«ã‚€ã‹ãƒã‚§ãƒƒã‚¯
                if not re.search(r'\d+', value):
                    issues.append(f"{field}ãŒæ•°å€¤ã‚’å«ã‚“ã§ã„ãªã„: {value}")
                    consistency_score -= 0.15

    # ãƒªã‚¹ãƒˆå‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
    list_fields = ['attendees', 'tags', 'subjects']
    for field in list_fields:
        if field in metadata:
            value = metadata[field]
            if not isinstance(value, list):
                issues.append(f"{field}ãŒãƒªã‚¹ãƒˆå‹ã§ã¯ãªã„: {type(value)}")
                consistency_score -= 0.15
            elif isinstance(value, list) and len(value) == 0:
                # ç©ºãƒªã‚¹ãƒˆã¯è»½å¾®ãªå•é¡Œ
                consistency_score -= 0.05

    # å­¦å¹´ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ (timetable, report_card ãªã©)
    if 'grade' in metadata:
        grade_value = metadata['grade']
        if isinstance(grade_value, str):
            # "å°å­¦Xå¹´", "ä¸­å­¦Xå¹´", "é«˜æ ¡Xå¹´" ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
            if not re.match(r'(å°å­¦|ä¸­å­¦|é«˜æ ¡)[1-6]å¹´', grade_value):
                issues.append(f"å­¦å¹´ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒä¸æ­£: {grade_value}")
                consistency_score -= 0.2

    # ã‚¹ã‚³ã‚¢ã¯0.0ä»¥ä¸‹ã«ã¯ãªã‚‰ãªã„
    consistency_score = max(0.0, consistency_score)

    if issues:
        logger.debug(f"ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã®å•é¡Œæ¤œå‡º: {len(issues)}ä»¶")
        for issue in issues:
            logger.debug(f"  - {issue}")

    logger.debug(f"ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã‚¹ã‚³ã‚¢: {consistency_score:.2f}")

    return consistency_score


def calculate_total_confidence(
    model_confidence: float,
    text: str,
    metadata: Dict[str, Any],
    doc_type: str
) -> Dict[str, float]:
    """
    è¤‡åˆæŒ‡æ¨™ã«ã‚ˆã‚‹ç·åˆä¿¡é ¼åº¦ã‚’è¨ˆç®—

    Args:
        model_confidence: AIãƒ¢ãƒ‡ãƒ«ã®ç¢ºä¿¡åº¦ (0.0 ~ 1.0)
        text: æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
        metadata: æŠ½å‡ºã•ã‚ŒãŸãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        doc_type: æ–‡æ›¸ã‚¿ã‚¤ãƒ—

    Returns:
        å„ã‚¹ã‚³ã‚¢ã¨ç·åˆä¿¡é ¼åº¦ã‚’å«ã‚€è¾æ›¸:
        {
            'model_confidence': float,
            'keyword_match_score': float,
            'metadata_completeness': float,
            'data_consistency': float,
            'total_confidence': float
        }
    """
    # å„æŒ‡æ¨™ã‚’è¨ˆç®—
    keyword_score = calculate_keyword_match_score(text, doc_type)
    completeness_score = calculate_metadata_completeness(metadata, doc_type)
    consistency_score = calculate_data_consistency(metadata, doc_type)

    # åŠ é‡å¹³å‡ã§ç·åˆä¿¡é ¼åº¦ã‚’è¨ˆç®—
    total_confidence = (
        model_confidence * 0.4 +
        keyword_score * 0.3 +
        completeness_score * 0.2 +
        consistency_score * 0.1
    )

    # çµæœã‚’ãƒ­ã‚°å‡ºåŠ›
    logger.info("=" * 60)
    logger.info("ğŸ“Š è¤‡åˆä¿¡é ¼åº¦è¨ˆç®—çµæœ")
    logger.info(f"  ãƒ¢ãƒ‡ãƒ«ç¢ºä¿¡åº¦ (40%):        {model_confidence:.3f}")
    logger.info(f"  ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä¸€è‡´ (30%):      {keyword_score:.3f}")
    logger.info(f"  ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å……è¶³ç‡ (20%):    {completeness_score:.3f}")
    logger.info(f"  ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ (10%):        {consistency_score:.3f}")
    logger.info(f"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    logger.info(f"  ç·åˆä¿¡é ¼åº¦:                {total_confidence:.3f}")
    logger.info("=" * 60)

    return {
        'model_confidence': model_confidence,
        'keyword_match_score': keyword_score,
        'metadata_completeness': completeness_score,
        'data_consistency': consistency_score,
        'total_confidence': total_confidence
    }


def get_confidence_level(total_confidence: float) -> str:
    """
    ç·åˆä¿¡é ¼åº¦ã‹ã‚‰ãƒ¬ãƒ™ãƒ«åˆ¤å®š

    Args:
        total_confidence: ç·åˆä¿¡é ¼åº¦ (0.0 ~ 1.0)

    Returns:
        ä¿¡é ¼åº¦ãƒ¬ãƒ™ãƒ« ("very_high", "high", "medium", "low", "very_low")
    """
    if total_confidence >= 0.9:
        return "very_high"
    elif total_confidence >= 0.75:
        return "high"
    elif total_confidence >= 0.6:
        return "medium"
    elif total_confidence >= 0.4:
        return "low"
    else:
        return "very_low"
