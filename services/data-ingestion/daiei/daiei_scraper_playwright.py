"""
ãƒ€ã‚¤ã‚¨ãƒ¼ãƒãƒƒãƒˆã‚¹ãƒ¼ãƒ‘ãƒ¼ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« (Playwrightç‰ˆ)

Playwrightã‚’ä½¿ç”¨ã—ã¦ãƒ­ã‚°ã‚¤ãƒ³çŠ¶æ…‹ã‚’ä¿æŒã—ãŸã¾ã¾å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã™ã€‚
"""

import json
import re
import time
import random
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional
from playwright.async_api import async_playwright, Browser, Page, BrowserContext

# ãƒ­ã‚¬ãƒ¼è¨­å®š
logger = logging.getLogger(__name__)


class DaieiScraperPlaywright:
    """ãƒ€ã‚¤ã‚¨ãƒ¼ãƒãƒƒãƒˆã‚¹ãƒ¼ãƒ‘ãƒ¼ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¯ãƒ©ã‚¹ (Playwrightç‰ˆ)"""

    def __init__(self):
        self.base_url = "https://netsuper.daiei.co.jp"
        self.playwright = None
        self.browser: Optional[Browser] = None
        self.context: Optional[BrowserContext] = None
        self.page: Optional[Page] = None
        self.store_id: Optional[str] = None  # åº—èˆ—IDï¼ˆãƒ­ã‚°ã‚¤ãƒ³å¾Œã«å–å¾—ï¼‰

    async def __aenter__(self):
        """async withæ§‹æ–‡ã§ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé–‹å§‹"""
        await self.start()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """async withæ§‹æ–‡ã§ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆçµ‚äº†"""
        await self.close()

    async def start(self, headless: bool = True):
        """
        ãƒ–ãƒ©ã‚¦ã‚¶ã‚’èµ·å‹•

        Args:
            headless: ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ã§èµ·å‹•ã™ã‚‹ã‹
        """
        try:
            self.playwright = await async_playwright().start()
            self.browser = await self.playwright.chromium.launch(headless=headless)
            self.context = await self.browser.new_context(
                viewport={'width': 1280, 'height': 800},
                user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            )
            self.page = await self.context.new_page()
            logger.info("âœ… Playwrightãƒ–ãƒ©ã‚¦ã‚¶èµ·å‹•å®Œäº†")

        except Exception as e:
            logger.error(f"ãƒ–ãƒ©ã‚¦ã‚¶èµ·å‹•ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            raise

    async def close(self):
        """ãƒ–ãƒ©ã‚¦ã‚¶ã‚’é–‰ã˜ã‚‹"""
        try:
            if self.page:
                await self.page.close()
            if self.context:
                await self.context.close()
            if self.browser:
                await self.browser.close()
            if self.playwright:
                await self.playwright.stop()
            logger.info("âœ… ãƒ–ãƒ©ã‚¦ã‚¶çµ‚äº†")

        except Exception as e:
            logger.error(f"ãƒ–ãƒ©ã‚¦ã‚¶çµ‚äº†ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)

    async def _is_logged_in(self) -> bool:
        """ãƒ­ã‚°ã‚¤ãƒ³çŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯"""
        try:
            # ãƒ­ã‚°ã‚¤ãƒ³ãƒ•ã‚©ãƒ¼ãƒ ãŒè¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            login_form = await self.page.query_selector('input[name="login_id"]')
            if login_form:
                # ãƒ­ã‚°ã‚¤ãƒ³ãƒ•ã‚©ãƒ¼ãƒ ãŒè¦‹ã¤ã‹ã£ãŸ = ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ã„ãªã„
                return False

            # åº—èˆ—IDã‚’å«ã‚€URLï¼ˆ/0XXX/ï¼‰ãªã‚‰ãƒ­ã‚°ã‚¤ãƒ³æ¸ˆã¿
            current_url = self.page.url
            import re
            if re.search(r'/0\d{3}/', current_url):
                return True

            return False
        except:
            return False

    async def login(self, login_id: str, password: str) -> bool:
        """
        ãƒ€ã‚¤ã‚¨ãƒ¼ãƒãƒƒãƒˆã‚¹ãƒ¼ãƒ‘ãƒ¼ã«ãƒ­ã‚°ã‚¤ãƒ³

        Args:
            login_id: ãƒ­ã‚°ã‚¤ãƒ³ID
            password: ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰

        Returns:
            æˆåŠŸã—ãŸã‚‰True
        """
        import asyncio

        try:
            logger.info("ğŸ” ãƒ€ã‚¤ã‚¨ãƒ¼ãƒãƒƒãƒˆã‚¹ãƒ¼ãƒ‘ãƒ¼ã«ãƒ­ã‚°ã‚¤ãƒ³ä¸­...")

            # ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹
            await self.page.goto(self.base_url, wait_until="domcontentloaded", timeout=60000)
            await self.page.wait_for_timeout(2000)

            # æ—¢ã«ãƒ­ã‚°ã‚¤ãƒ³æ¸ˆã¿ã‹ãƒã‚§ãƒƒã‚¯
            if await self._is_logged_in():
                logger.info("âœ… æ—¢ã«ãƒ­ã‚°ã‚¤ãƒ³æ¸ˆã¿ã§ã™")
                return True

            # ãƒ­ã‚°ã‚¤ãƒ³ãƒ•ã‚©ãƒ¼ãƒ ã‚’è¦‹ã¤ã‘ã‚‹
            logger.info("ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ­ã‚°ã‚¤ãƒ³IDã‚’å…¥åŠ›ä¸­...")

            # ãƒ­ã‚°ã‚¤ãƒ³IDã‚’å…¥åŠ›
            login_id_input = await self.page.wait_for_selector(
                'input[name="login_id"]',
                timeout=10000,
                state="visible"
            )
            await login_id_input.click()
            await login_id_input.fill(login_id)
            logger.info("âœ… ãƒ­ã‚°ã‚¤ãƒ³IDå…¥åŠ›å®Œäº†")

            # ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›
            logger.info("ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ä¸­...")
            password_input = await self.page.wait_for_selector(
                'input[name="password"]',
                timeout=5000,
                state="visible"
            )
            await password_input.click()
            await password_input.fill(password)
            logger.info("âœ… ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰å…¥åŠ›å®Œäº†")

            # ãƒ­ã‚°ã‚¤ãƒ³ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
            await asyncio.sleep(0.5)
            login_button = await self.page.wait_for_selector(
                'button.p-mvLogin__submit, button[onclick*="LoginRun"]',
                timeout=5000,
                state="visible"
            )
            await login_button.click()
            logger.info("ãƒ­ã‚°ã‚¤ãƒ³ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯")

            # ãƒ­ã‚°ã‚¤ãƒ³å®Œäº†ã‚’å¾…æ©Ÿ
            await asyncio.sleep(3)
            await self.page.wait_for_load_state("domcontentloaded")

            current_url = self.page.url
            logger.info(f"ãƒ­ã‚°ã‚¤ãƒ³å¾Œã®URL: {current_url}")

            # ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸç¢ºèª
            if await self._is_logged_in():
                logger.info("âœ… ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸ")

                # WAONãƒã‚¤ãƒ³ãƒˆæ¡ˆå†…ãƒšãƒ¼ã‚¸ãŒè¡¨ç¤ºã•ã‚Œã‚‹å ´åˆãŒã‚ã‚‹ã®ã§ã€ã‚¹ã‚­ãƒƒãƒ—
                await asyncio.sleep(1)
                shopping_button = await self.page.query_selector('a[href*="submit_apc_shopping"]')
                if shopping_button:
                    logger.info("WAONãƒã‚¤ãƒ³ãƒˆæ¡ˆå†…ãƒšãƒ¼ã‚¸ã‚’ã‚¹ã‚­ãƒƒãƒ—ä¸­...")
                    await shopping_button.click()
                    await asyncio.sleep(2)
                    await self.page.wait_for_load_state("domcontentloaded")
                    logger.info("âœ… ãŠè²·ã„ç‰©ãƒšãƒ¼ã‚¸ã«é·ç§»")

                return True
            else:
                logger.error("âŒ ãƒ­ã‚°ã‚¤ãƒ³å¤±æ•—")
                return False

        except Exception as e:
            logger.error(f"ãƒ­ã‚°ã‚¤ãƒ³ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return False

    async def select_delivery_slot(self) -> bool:
        """
        é…é”æ—¥æ™‚ã‚’é¸æŠï¼ˆåˆ©ç”¨å¯èƒ½ãªæœ€åˆã®é…é”ä¾¿ã‚’é¸æŠï¼‰

        Returns:
            æˆåŠŸã—ãŸã‚‰True
        """
        import asyncio

        try:
            logger.info("ğŸ“¦ é…é”æ—¥æ™‚ã‚’é¸æŠä¸­...")

            # é…é”ä¾¿é¸æŠãƒšãƒ¼ã‚¸ã‚’å¾…æ©Ÿ
            await self.page.wait_for_timeout(2000)

            # åˆ©ç”¨å¯èƒ½ãªé…é”ä¾¿ã®ãƒ©ãƒ™ãƒ«ã‚’æ¢ã™
            # class="acceptable" (â—‹å—ä»˜ä¸­) ã¾ãŸã¯ class="a-little" (â–³æ®‹ã‚Šã‚ãšã‹)
            available_labels = await self.page.query_selector_all(
                'label.acceptable, label.a-little'
            )

            if not available_labels:
                logger.error("âŒ åˆ©ç”¨å¯èƒ½ãªé…é”ä¾¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return False

            logger.info(f"åˆ©ç”¨å¯èƒ½ãªé…é”ä¾¿: {len(available_labels)}ä»¶")

            # æœ€åˆã®åˆ©ç”¨å¯èƒ½ãªé…é”ä¾¿ã‚’é¸æŠ
            first_label = available_labels[0]
            label_id = await first_label.get_attribute("id")
            logger.info(f"é…é”ä¾¿ãƒ©ãƒ™ãƒ«ã‚’é¸æŠ: {label_id}")

            # ãƒ©ãƒ™ãƒ«ã‚’ã‚¯ãƒªãƒƒã‚¯ï¼ˆå†…éƒ¨ã®inputãŒé¸æŠã•ã‚Œã‚‹ï¼‰
            await first_label.click()
            await asyncio.sleep(1)

            # ã€ŒãŠè²·ã„ç‰©ã‚’å§‹ã‚ã‚‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
            # ã“ã®ãƒœã‚¿ãƒ³ã¯é…é”ä¾¿é¸æŠå¾Œã«æœ‰åŠ¹ã«ãªã‚‹
            start_shopping_button = await self.page.wait_for_selector(
                'button[type="button"], input[type="button"], a[href*="index.php"]',
                timeout=10000,
                state="visible"
            )

            # ãƒœã‚¿ãƒ³ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¢ºèª
            button_text = await start_shopping_button.inner_text()
            logger.info(f"ãƒœã‚¿ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {button_text}")

            await start_shopping_button.click()
            logger.info("ãŠè²·ã„ç‰©ã‚’å§‹ã‚ã‚‹ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯")

            await asyncio.sleep(2)
            await self.page.wait_for_load_state("domcontentloaded")

            # åº—èˆ—IDã‚’URLã‹ã‚‰å–å¾—
            current_url = self.page.url
            match = re.search(r'/(\d{4})/', current_url)
            if match:
                self.store_id = match.group(1)
                logger.info(f"âœ… åº—èˆ—IDå–å¾—: {self.store_id}")
            else:
                logger.warning("âš ï¸ åº—èˆ—IDãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")

            logger.info(f"ç¾åœ¨ã®URL: {current_url}")
            logger.info("âœ… é…é”æ—¥æ™‚é¸æŠå®Œäº†")
            return True

        except Exception as e:
            logger.error(f"é…é”æ—¥æ™‚é¸æŠã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return False

    async def fetch_products_page(
        self,
        category_url: str,
        page: int = 1
    ) -> tuple[List[Dict[str, Any]], Optional[dict]]:
        """
        ã‚«ãƒ†ã‚´ãƒªãƒ¼ãƒšãƒ¼ã‚¸ã®å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—

        Args:
            category_url: ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®å®Œå…¨URL
            page: ãƒšãƒ¼ã‚¸ç•ªå·ï¼ˆ1å§‹ã¾ã‚Šã€å†…éƒ¨çš„ã«page=0ã«å¤‰æ›ã•ã‚Œã‚‹ï¼‰

        Returns:
            (å•†å“ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ, ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±)
        """
        try:
            # ãƒ€ã‚¤ã‚¨ãƒ¼ã®ãƒšãƒ¼ã‚¸ç•ªå·ã¯0å§‹ã¾ã‚Šï¼ˆpage=0ãŒ1ãƒšãƒ¼ã‚¸ç›®ï¼‰
            # å¼•æ•°ã¯1å§‹ã¾ã‚Šã§å—ã‘å–ã‚Šã€å†…éƒ¨ã§0å§‹ã¾ã‚Šã«å¤‰æ›
            actual_page = page - 1

            # URLã«ãƒšãƒ¼ã‚¸ç•ªå·ã‚’è¿½åŠ 
            if '?' in category_url:
                url = f"{category_url}&page={actual_page}"
            else:
                url = f"{category_url}?page={actual_page}"

            logger.info(f"å•†å“ãƒšãƒ¼ã‚¸å–å¾—ä¸­ (page={page}â†’{actual_page}): {url}")

            await self.page.goto(url, wait_until="networkidle", timeout=60000)
            await self.page.wait_for_timeout(3000)

            # å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºï¼ˆHTMLãƒ™ãƒ¼ã‚¹ï¼‰
            products, pagination_info = await self._extract_products_from_html()

            # ã‚¢ã‚¯ã‚»ã‚¹é–“éš”åˆ¶å¾¡
            await self.page.wait_for_timeout(random.randint(1000, 2000))

            return products, pagination_info

        except Exception as e:
            logger.error(f"å•†å“ãƒšãƒ¼ã‚¸å–å¾—ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return [], None

    async def _extract_products_from_html(self) -> tuple[List[Dict[str, Any]], Optional[dict]]:
        """
        HTMLã‹ã‚‰å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º

        Returns:
            (å•†å“ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ, ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±)
        """
        try:
            logger.info("âœ… HTMLè§£æé–‹å§‹")

            # ãƒ‡ãƒãƒƒã‚°ç”¨ã«ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆãƒ»HTMLä¿å­˜
            await self.page.screenshot(path="daiei_product_page.png")
            logger.info("ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆä¿å­˜: daiei_product_page.png")

            html_content = await self.page.content()
            with open("daiei_product_page.html", "w", encoding="utf-8") as f:
                f.write(html_content)
            logger.info("HTMLä¿å­˜: daiei_product_page.html")

            # å•†å“ã‚³ãƒ³ãƒ†ãƒŠã‚’å–å¾—
            product_containers = await self.page.query_selector_all('div.item_ct')
            logger.info(f"å•†å“ã‚³ãƒ³ãƒ†ãƒŠæ•°: {len(product_containers)}")

            products = []

            for container in product_containers:
                try:
                    # å•†å“IDã‚’å–å¾—
                    id_anchor = await container.query_selector('a[id]')
                    product_id = await id_anchor.get_attribute('id') if id_anchor else None

                    # å•†å“åã¨URLã‚’å–å¾—
                    name_elem = await container.query_selector('div.item_name a')
                    product_name = await name_elem.inner_text() if name_elem else None
                    product_url = None
                    if name_elem:
                        href = await name_elem.get_attribute('href')
                        if href:
                            if href.startswith('http'):
                                product_url = href
                            elif href.startswith('/'):
                                product_url = f"https://netsuper.daiei.co.jp{href}"
                            else:
                                product_url = f"https://netsuper.daiei.co.jp/{href}"

                    # å•†å“ç”»åƒURLã‚’å–å¾—
                    img_elem = await container.query_selector('div.item_img img')
                    img_src = await img_elem.get_attribute('src') if img_elem else None
                    if img_src and not img_src.startswith('http'):
                        img_src = f"https://netsuper.daiei.co.jp{img_src}"

                    # æœ¬ä½“ä¾¡æ ¼ã‚’å–å¾—
                    price_elem = await container.query_selector('span.item_price')
                    base_price_text = await price_elem.inner_text() if price_elem else None
                    base_price = float(base_price_text) if base_price_text and base_price_text.isdigit() else None

                    # ç¨è¾¼ä¾¡æ ¼ã‚’å–å¾—
                    tax_price_elem = await container.query_selector('p.item_price2')
                    tax_price_text = await tax_price_elem.inner_text() if tax_price_elem else None
                    tax_price = None
                    if tax_price_text:
                        import re
                        match = re.search(r'([\d,]+\.?\d*)å††', tax_price_text)
                        if match:
                            tax_price = float(match.group(1).replace(',', ''))

                    product = {
                        "product_id": product_id,
                        "product_name": product_name,
                        "price": base_price,
                        "price_tax_included": tax_price,
                        "image_url": img_src,
                        "url": product_url,  # URLã‚’è¿½åŠ 
                        "in_stock": True,  # ãƒšãƒ¼ã‚¸ã«è¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹ = åœ¨åº«ã‚ã‚Š
                        "is_available": True,
                        "raw_data": {
                            "product_id": product_id,
                            "base_price": base_price,
                            "tax_price": tax_price,
                            "url": product_url  # raw_dataã«ã‚‚è¿½åŠ 
                        }
                    }

                    products.append(product)

                except Exception as e:
                    logger.warning(f"å•†å“ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¨ãƒ©ãƒ¼ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰: {e}")
                    continue

            # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±ã‚’å–å¾—
            pagination_info = None
            try:
                pagination_text_elem = await self.page.query_selector('text="ãƒ’ãƒƒãƒˆæ•°ï¼š"')
                if pagination_text_elem:
                    parent = await pagination_text_elem.evaluate_handle('node => node.parentElement')
                    text = await parent.inner_text()
                    import re
                    # "ãƒ’ãƒƒãƒˆæ•°ï¼š205ä»¶ 2/6ãƒšãƒ¼ã‚¸" ã®ã‚ˆã†ãªå½¢å¼
                    total_match = re.search(r'(\d+)ä»¶', text)
                    page_match = re.search(r'(\d+)/(\d+)ãƒšãƒ¼ã‚¸', text)

                    if total_match and page_match:
                        total_items = int(total_match.group(1))
                        current_page = int(page_match.group(1))
                        total_pages = int(page_match.group(2))

                        pagination_info = {
                            "totalItems": total_items,
                            "currentPage": current_page,
                            "totalPages": total_pages,
                            "itemsPerPage": len(products),
                            "source": "html:pagination_text"
                        }
            except Exception as e:
                logger.warning(f"ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

            logger.info(f"âœ… å•†å“æŠ½å‡ºå®Œäº†: {len(products)}ä»¶")

            return products, pagination_info

        except Exception as e:
            logger.error(f"å•†å“æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return [], None


async def main():
    """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œç”¨ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    import os
    from dotenv import load_dotenv
    load_dotenv()

    login_id = os.getenv("DAIEI_LOGIN_ID")
    password = os.getenv("DAIEI_PASSWORD")

    if not login_id or not password:
        logger.error("âŒ ç’°å¢ƒå¤‰æ•° DAIEI_LOGIN_ID ã¨ DAIEI_PASSWORD ã‚’è¨­å®šã—ã¦ãã ã•ã„")
        return

    scraper = DaieiScraperPlaywright()

    try:
        # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ã‚’ã‚ªãƒ•ã«ã—ã¦ãƒ–ãƒ©ã‚¦ã‚¶ã‚’è¡¨ç¤º
        await scraper.start(headless=False)

        # ãƒ­ã‚°ã‚¤ãƒ³
        success = await scraper.login(login_id, password)
        if not success:
            logger.error("âŒ ãƒ­ã‚°ã‚¤ãƒ³å¤±æ•—")
            return

        # é…é”æ—¥æ™‚é¸æŠãƒšãƒ¼ã‚¸ã®HTMLã‚’ä¿å­˜
        await scraper.page.screenshot(path="daiei_delivery_page.png")
        html_content = await scraper.page.content()
        with open("daiei_delivery_page.html", "w", encoding="utf-8") as f:
            f.write(html_content)
        logger.info("ğŸ“¸ é…é”æ—¥æ™‚é¸æŠãƒšãƒ¼ã‚¸ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆãƒ»HTMLä¿å­˜å®Œäº†")

        # é…é”æ—¥æ™‚é¸æŠ
        success = await scraper.select_delivery_slot()
        if not success:
            logger.error("âŒ é…é”æ—¥æ™‚é¸æŠå¤±æ•—")
            # å¤±æ•—æ™‚ã‚‚å°‘ã—å¾…ã¤ï¼ˆç”»é¢ç¢ºèªã®ãŸã‚ï¼‰
            await scraper.page.wait_for_timeout(5000)
            return

        # æˆåŠŸå¾Œã€å•†å“ãƒšãƒ¼ã‚¸ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆãƒ»HTMLä¿å­˜
        await scraper.page.screenshot(path="daiei_product_top.png")
        html_content = await scraper.page.content()
        with open("daiei_product_top.html", "w", encoding="utf-8") as f:
            f.write(html_content)
        logger.info("ğŸ“¸ å•†å“ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆãƒ»HTMLä¿å­˜å®Œäº†")

        # ãƒ†ã‚¹ãƒˆ: ã‚«ãƒ†ã‚´ãƒªãƒ¼ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹ï¼ˆé‡èœæœç‰©ï¼‰
        test_category_url = f"https://netsuper.daiei.co.jp/{scraper.store_id}/item/item.php?classL=2&classS=1&ilc_code=1001"
        logger.info(f"ğŸ“¦ ãƒ†ã‚¹ãƒˆã‚«ãƒ†ã‚´ãƒªãƒ¼ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹: {test_category_url}")

        products, pagination = await scraper.fetch_products_page(test_category_url, page=1)
        logger.info(f"âœ… å•†å“å–å¾—å®Œäº†: {len(products)}ä»¶")
        if pagination:
            logger.info(f"ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±: {pagination}")

        logger.info("âœ… ãƒ†ã‚¹ãƒˆå®Œäº†")

        # ç”»é¢ã‚’ç¢ºèªã§ãã‚‹ã‚ˆã†ã«5ç§’å¾…ã¤
        await scraper.page.wait_for_timeout(5000)

    finally:
        await scraper.close()


if __name__ == "__main__":
    import asyncio
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    asyncio.run(main())
