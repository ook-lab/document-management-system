# æœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤ã‚¬ã‚¤ãƒ‰

## æ¦‚è¦

ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ã€ä»¥ä¸‹ã®4ã¤ã®é«˜åº¦ãªæ¤œç´¢æ©Ÿèƒ½ã‚’æœ¬ç•ªç’°å¢ƒã«ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹æ‰‹é †ã‚’èª¬æ˜Žã—ã¾ã™ï¼š

1. âœ… ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ï¼ˆãƒ™ã‚¯ãƒˆãƒ« + å…¨æ–‡æ¤œç´¢ï¼‰
2. âœ… ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
3. âœ… Parent-Child Indexing
4. âœ… Hypothetical Questions (ä»®æƒ³è³ªå•ç”Ÿæˆ)
5. âœ… ãƒªãƒ©ãƒ³ã‚¯ï¼ˆRerankingï¼‰

---

## ðŸ“‹ ãƒ‡ãƒ—ãƒ­ã‚¤å‰ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### ç’°å¢ƒç¢ºèª

- [ ] Supabaseãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¸ã®ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™
- [ ] ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å–å¾—æ¸ˆã¿
- [ ] æœ¬ç•ªç’°å¢ƒã®`.env`ãƒ•ã‚¡ã‚¤ãƒ«æº–å‚™æ¸ˆã¿
- [ ] ä¾å­˜é–¢ä¿‚ã®ç¢ºèª

### å¿…è¦ãªAPIã‚­ãƒ¼

- [ ] `SUPABASE_URL` - Supabaseãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ URL
- [ ] `SUPABASE_KEY` - Supabase API Key
- [ ] `OPENAI_API_KEY` - OpenAI API Keyï¼ˆembeddingsç”¨ï¼‰
- [ ] `ANTHROPIC_API_KEY` - Claude API Keyï¼ˆextractionç”¨ï¼‰
- [ ] `GOOGLE_API_KEY` - Gemini API Keyï¼ˆVisionç”¨ï¼‰
- [ ] `COHERE_API_KEY` - Cohere API Keyï¼ˆRerankç”¨ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

---

## ðŸ—„ï¸ ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒžæ›´æ–°

### é‡è¦ãªæ³¨æ„äº‹é …

âš ï¸ **ä»¥ä¸‹ã®SQLã‚’å®Ÿè¡Œã™ã‚‹å‰ã«å¿…ãšãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å–å¾—ã—ã¦ãã ã•ã„**

Supabaseãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ â†’ Database â†’ Backups â†’ Create Backup

### å®Ÿè¡Œé †åº

SQLãƒ•ã‚¡ã‚¤ãƒ«ã¯ä»¥ä¸‹ã®é †ç•ªã§å®Ÿè¡Œã—ã¦ãã ã•ã„ï¼š

#### 1.1 å…¨æ–‡æ¤œç´¢ã®è¿½åŠ 

**ãƒ•ã‚¡ã‚¤ãƒ«**: `database/schema_updates/add_fulltext_search.sql`

**å®Ÿè¡Œå†…å®¹**:
- `documents.full_text_tsv` ã‚«ãƒ©ãƒ è¿½åŠ 
- `document_chunks.chunk_text_tsv` ã‚«ãƒ©ãƒ è¿½åŠ 
- GINã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
- `hybrid_search_chunks()` é–¢æ•°ä½œæˆ
- `keyword_search_chunks()` é–¢æ•°ä½œæˆ

**å®Ÿè¡Œæ–¹æ³•**:
```bash
# ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’ã‚³ãƒ”ãƒ¼
cat database/schema_updates/add_fulltext_search.sql

# Supabase SQL Editorã«ãƒšãƒ¼ã‚¹ãƒˆ â†’ Run
```

**ç¢ºèª**:
```sql
-- ã‚«ãƒ©ãƒ ãŒè¿½åŠ ã•ã‚ŒãŸã‹ç¢ºèª
SELECT column_name, data_type
FROM information_schema.columns
WHERE table_name = 'documents' AND column_name = 'full_text_tsv';

-- é–¢æ•°ãŒä½œæˆã•ã‚ŒãŸã‹ç¢ºèª
SELECT routine_name
FROM information_schema.routines
WHERE routine_name IN ('hybrid_search_chunks', 'keyword_search_chunks');
```

**æœŸå¾…ã•ã‚Œã‚‹çµæžœ**: ã‚«ãƒ©ãƒ ã¨é–¢æ•°ãŒå­˜åœ¨ã™ã‚‹ã“ã¨

---

#### 1.2 ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã®è¿½åŠ 

**ãƒ•ã‚¡ã‚¤ãƒ«**: `database/schema_updates/add_metadata_filtering.sql`

**å®Ÿè¡Œå†…å®¹**:
- `documents.year`, `month`, `amount` ãªã©ã®ã‚«ãƒ©ãƒ è¿½åŠ 
- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
- `match_document_chunks()` é–¢æ•°ã®æ›´æ–°ï¼ˆãƒ•ã‚£ãƒ«ã‚¿å¯¾å¿œï¼‰

**å®Ÿè¡Œæ–¹æ³•**:
```bash
cat database/schema_updates/add_metadata_filtering.sql
# Supabase SQL Editorã«ãƒšãƒ¼ã‚¹ãƒˆ â†’ Run
```

**ç¢ºèª**:
```sql
-- ã‚«ãƒ©ãƒ ãŒè¿½åŠ ã•ã‚ŒãŸã‹ç¢ºèª
SELECT column_name
FROM information_schema.columns
WHERE table_name = 'documents'
  AND column_name IN ('year', 'month', 'amount', 'grade_level');
```

**æœŸå¾…ã•ã‚Œã‚‹çµæžœ**: 4ã¤ã®ã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã™ã‚‹ã“ã¨

---

#### 1.3 Parent-Child Indexingã®è¿½åŠ 

**ãƒ•ã‚¡ã‚¤ãƒ«**: `database/schema_updates/add_parent_child_indexing.sql`

**å®Ÿè¡Œå†…å®¹**:
- `document_chunks.parent_chunk_id` ã‚«ãƒ©ãƒ è¿½åŠ 
- `document_chunks.is_parent` ã‚«ãƒ©ãƒ è¿½åŠ 
- `document_chunks.chunk_level` ã‚«ãƒ©ãƒ è¿½åŠ 
- `hybrid_search_with_parent_child()` é–¢æ•°ä½œæˆ

**å®Ÿè¡Œæ–¹æ³•**:
```bash
cat database/schema_updates/add_parent_child_indexing.sql
# Supabase SQL Editorã«ãƒšãƒ¼ã‚¹ãƒˆ â†’ Run
```

**ç¢ºèª**:
```sql
-- ã‚«ãƒ©ãƒ ãŒè¿½åŠ ã•ã‚ŒãŸã‹ç¢ºèª
SELECT column_name
FROM information_schema.columns
WHERE table_name = 'document_chunks'
  AND column_name IN ('parent_chunk_id', 'is_parent', 'chunk_level');

-- é–¢æ•°ãŒä½œæˆã•ã‚ŒãŸã‹ç¢ºèª
SELECT routine_name
FROM information_schema.routines
WHERE routine_name = 'hybrid_search_with_parent_child';
```

**æœŸå¾…ã•ã‚Œã‚‹çµæžœ**: 3ã¤ã®ã‚«ãƒ©ãƒ ã¨é–¢æ•°ãŒå­˜åœ¨ã™ã‚‹ã“ã¨

---

#### 1.4 Hypothetical Questionsã®è¿½åŠ 

**ãƒ•ã‚¡ã‚¤ãƒ«**: `database/schema_updates/add_hypothetical_questions.sql`

**å®Ÿè¡Œå†…å®¹**:
- `hypothetical_questions` ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
- `search_hypothetical_questions()` é–¢æ•°ä½œæˆ
- `hybrid_search_with_questions()` é–¢æ•°ä½œæˆ

**å®Ÿè¡Œæ–¹æ³•**:
```bash
cat database/schema_updates/add_hypothetical_questions.sql
# Supabase SQL Editorã«ãƒšãƒ¼ã‚¹ãƒˆ â†’ Run
```

**ç¢ºèª**:
```sql
-- ãƒ†ãƒ¼ãƒ–ãƒ«ãŒä½œæˆã•ã‚ŒãŸã‹ç¢ºèª
SELECT table_name
FROM information_schema.tables
WHERE table_name = 'hypothetical_questions';

-- é–¢æ•°ãŒä½œæˆã•ã‚ŒãŸã‹ç¢ºèª
SELECT routine_name
FROM information_schema.routines
WHERE routine_name IN ('search_hypothetical_questions', 'hybrid_search_with_questions');
```

**æœŸå¾…ã•ã‚Œã‚‹çµæžœ**: ãƒ†ãƒ¼ãƒ–ãƒ«ã¨2ã¤ã®é–¢æ•°ãŒå­˜åœ¨ã™ã‚‹ã“ã¨

---

### ã‚¹ã‚­ãƒ¼ãƒžæ›´æ–°å®Œäº†ã®ç¢ºèª

å…¨ã¦ã®ã‚¹ã‚­ãƒ¼ãƒžæ›´æ–°ãŒå®Œäº†ã—ãŸã‚‰ã€ä»¥ä¸‹ã®SQLã§ç¢ºèªï¼š

```sql
-- å…¨ã¦ã®æ–°ã—ã„ã‚«ãƒ©ãƒ ã‚’ç¢ºèª
SELECT
    table_name,
    column_name,
    data_type
FROM information_schema.columns
WHERE table_name IN ('documents', 'document_chunks', 'hypothetical_questions')
  AND column_name IN (
    'full_text_tsv', 'chunk_text_tsv',
    'year', 'month', 'amount', 'grade_level', 'school_name', 'event_dates',
    'parent_chunk_id', 'is_parent', 'chunk_level',
    'question_text', 'question_embedding', 'confidence_score'
  )
ORDER BY table_name, column_name;

-- å…¨ã¦ã®æ–°ã—ã„é–¢æ•°ã‚’ç¢ºèª
SELECT routine_name
FROM information_schema.routines
WHERE routine_name IN (
    'hybrid_search_chunks',
    'keyword_search_chunks',
    'hybrid_search_with_parent_child',
    'search_hypothetical_questions',
    'hybrid_search_with_questions'
)
ORDER BY routine_name;
```

**æœŸå¾…ã•ã‚Œã‚‹çµæžœ**:
- ã‚«ãƒ©ãƒ : 13å€‹ä»¥ä¸Š
- é–¢æ•°: 5å€‹

---

## ðŸ ã‚¹ãƒ†ãƒƒãƒ—2: ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

### Pythonä¾å­˜é–¢ä¿‚ã®ç¢ºèª

```bash
# ä»®æƒ³ç’°å¢ƒãŒã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‹ç¢ºèª
which python
# æœŸå¾…: /path/to/venv/bin/python

# ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
source venv/bin/activate
pip install -r requirements.txt

# æ–°ã—ã„ä¾å­˜é–¢ä¿‚ã‚’å€‹åˆ¥ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install cohere>=4.0.0 sentence-transformers>=2.2.0
```

### ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª

```bash
# ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒæ­£ã—ãã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚ŒãŸã‹ç¢ºèª
python -c "import cohere; print('Cohere:', cohere.__version__)"
python -c "import sentence_transformers; print('Sentence Transformers:', sentence_transformers.__version__)"
```

**æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›**:
```
Cohere: 5.20.0
Sentence Transformers: 5.1.2
```

---

## âš™ï¸ ã‚¹ãƒ†ãƒƒãƒ—3: ç’°å¢ƒå¤‰æ•°ã®è¨­å®š

### .envãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª

`.env`ãƒ•ã‚¡ã‚¤ãƒ«ã«ä»¥ä¸‹ã®å¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªï¼š

```bash
# å¿…é ˆ
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_KEY=your_supabase_key
OPENAI_API_KEY=your_openai_key
ANTHROPIC_API_KEY=your_anthropic_key
GOOGLE_API_KEY=your_google_key

# ãƒªãƒ©ãƒ³ã‚¯ç”¨ï¼ˆæŽ¨å¥¨ï¼‰
RERANK_ENABLED=true
RERANK_PROVIDER=cohere  # ã¾ãŸã¯ huggingface
RERANK_INITIAL_COUNT=50
RERANK_FINAL_COUNT=5
COHERE_API_KEY=your_cohere_key  # cohereã‚’ä½¿ã†å ´åˆ

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š
PORT=5001
FLASK_ENV=production
```

### ç’°å¢ƒå¤‰æ•°ã®æ¤œè¨¼

```bash
# ç’°å¢ƒå¤‰æ•°ãŒæ­£ã—ãèª­ã¿è¾¼ã¾ã‚Œã‚‹ã‹ç¢ºèª
python -c "
from dotenv import load_dotenv
import os
load_dotenv()
print('SUPABASE_URL:', os.getenv('SUPABASE_URL')[:30] + '...')
print('RERANK_ENABLED:', os.getenv('RERANK_ENABLED'))
print('RERANK_PROVIDER:', os.getenv('RERANK_PROVIDER'))
"
```

**æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›**:
```
SUPABASE_URL: https://your-project.supabase...
RERANK_ENABLED: true
RERANK_PROVIDER: cohere
```

---

## ðŸš€ ã‚¹ãƒ†ãƒƒãƒ—4: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•ãƒ†ã‚¹ãƒˆ

### èµ·å‹•å‰ã®ç¢ºèª

```bash
# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æŽ¥ç¶šãƒ†ã‚¹ãƒˆ
python -c "
from core.database.client import DatabaseClient
db = DatabaseClient()
print('âœ… Database client initialized')
"
```

### ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•

```bash
# Flaskã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’èµ·å‹•
python app.py
```

**æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›**:
```
 * Running on http://0.0.0.0:5001
 * Restarting with stat
```

### èµ·å‹•ç¢ºèª

åˆ¥ã®ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ï¼š
```bash
# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
curl http://localhost:5001/api/health

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:
# {"status":"ok","message":"Document Q&A System is running"}
```

---

## ðŸ§ª ã‚¹ãƒ†ãƒƒãƒ—5: æ©Ÿèƒ½å‹•ä½œç¢ºèª

### ãƒ†ã‚¹ãƒˆ1: ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢

```bash
# ãƒ†ã‚¹ãƒˆç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆä½œæˆ
cat > test_hybrid_search.py << 'EOF'
import asyncio
from core.database.client import DatabaseClient
from core.ai.llm_client import LLMClient

async def test_hybrid_search():
    db = DatabaseClient()
    llm = LLMClient()

    # ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª
    query = "2023å¹´12æœˆã®äºˆå®š"
    embedding = llm.generate_embedding(query)

    # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢
    results = await db.hybrid_search_chunks(
        query_text=query,
        query_embedding=embedding,
        limit=5
    )

    print(f"âœ… ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢: {len(results)}ä»¶ãƒ’ãƒƒãƒˆ")
    if results:
        print(f"   ãƒˆãƒƒãƒ—çµæžœ: {results[0].get('chunk_text', '')[:50]}...")

asyncio.run(test_hybrid_search())
EOF

python test_hybrid_search.py
```

**æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›**:
```
ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢æˆåŠŸ: 5 ä»¶ã®ãƒãƒ£ãƒ³ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ
  é‡ã¿é…åˆ†: ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢=70%, å…¨æ–‡æ¤œç´¢=30%
âœ… ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢: 5ä»¶ãƒ’ãƒƒãƒˆ
```

---

### ãƒ†ã‚¹ãƒˆ2: ãƒªãƒ©ãƒ³ã‚¯

```bash
cat > test_rerank.py << 'EOF'
from core.utils.reranker import Reranker, RerankConfig

# ãƒªãƒ©ãƒ³ã‚¯è¨­å®šç¢ºèª
print(f"ãƒªãƒ©ãƒ³ã‚¯æœ‰åŠ¹: {RerankConfig.ENABLED}")
print(f"ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: {RerankConfig.PROVIDER}")

# ãƒªãƒ©ãƒ³ã‚«ãƒ¼åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ
reranker = Reranker(provider=RerankConfig.PROVIDER)
print(f"âœ… ãƒªãƒ©ãƒ³ã‚«ãƒ¼åˆæœŸåŒ–æˆåŠŸ: {reranker.provider}")
EOF

python test_rerank.py
```

**æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›**:
```
ãƒªãƒ©ãƒ³ã‚¯æœ‰åŠ¹: True
ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: cohere
[Reranker] Cohere Rerank initialized
âœ… ãƒªãƒ©ãƒ³ã‚«ãƒ¼åˆæœŸåŒ–æˆåŠŸ: cohere
```

---

### ãƒ†ã‚¹ãƒˆ3: Parent-Child Indexing

```bash
cat > test_parent_child.py << 'EOF'
from core.utils.chunking import chunk_document_parent_child

# ãƒ†ã‚¹ãƒˆãƒ†ã‚­ã‚¹ãƒˆ
text = "ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆã§ã™ã€‚" * 500  # ç´„1500æ–‡å­—

# Parent-Childåˆ†å‰²
result = chunk_document_parent_child(
    text=text,
    parent_size=1500,
    child_size=300
)

print(f"âœ… Parent-Childåˆ†å‰²æˆåŠŸ")
print(f"   è¦ªãƒãƒ£ãƒ³ã‚¯: {len(result['parent_chunks'])}å€‹")
print(f"   å­ãƒãƒ£ãƒ³ã‚¯: {len(result['child_chunks'])}å€‹")
EOF

python test_parent_child.py
```

**æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›**:
```
Parent-Childåˆ†å‰²å®Œäº†: Xè¦ªãƒãƒ£ãƒ³ã‚¯ã€Yå­ãƒãƒ£ãƒ³ã‚¯
âœ… Parent-Childåˆ†å‰²æˆåŠŸ
   è¦ªãƒãƒ£ãƒ³ã‚¯: Xå€‹
   å­ãƒãƒ£ãƒ³ã‚¯: Yå€‹
```

---

### ãƒ†ã‚¹ãƒˆ4: Hypothetical Questions

```bash
cat > test_hypothetical_questions.py << 'EOF'
from core.utils.hypothetical_questions import HypotheticalQuestionGenerator
from core.ai.llm_client import LLMClient

llm = LLMClient()
generator = HypotheticalQuestionGenerator(llm)

# ãƒ†ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯
chunk_text = "2024å¹´12æœˆ4æ—¥ï¼ˆæ°´ï¼‰14:00-16:00 ç¤¾å†…MTG è­°é¡Œ:Q4æŒ¯ã‚Šè¿”ã‚Š"

# è³ªå•ç”Ÿæˆ
questions = generator.generate_questions(
    chunk_text=chunk_text,
    num_questions=3
)

print(f"âœ… è³ªå•ç”ŸæˆæˆåŠŸ: {len(questions)}å€‹")
for i, q in enumerate(questions, 1):
    print(f"   {i}. {q['question_text']} (confidence: {q['confidence_score']})")
EOF

python test_hypothetical_questions.py
```

**æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›**:
```
[HypotheticalQ] è³ªå•ç”ŸæˆæˆåŠŸ: 3ä»¶
âœ… è³ªå•ç”ŸæˆæˆåŠŸ: 3å€‹
   1. 12æœˆ4æ—¥ã®äºˆå®šã¯ï¼Ÿ (confidence: 1.0)
   2. Q4æŒ¯ã‚Šè¿”ã‚Šã®MTGã¯ã„ã¤ï¼Ÿ (confidence: 0.95)
   3. ç¤¾å†…MTGã®è­°é¡Œã¯ï¼Ÿ (confidence: 1.0)
```

---

### çµ±åˆãƒ†ã‚¹ãƒˆï¼ˆå®Ÿéš›ã®æ¤œç´¢ãƒ•ãƒ­ãƒ¼ï¼‰

```bash
# Webã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã§ãƒ†ã‚¹ãƒˆ
# ãƒ–ãƒ©ã‚¦ã‚¶ã§ http://localhost:5001 ã‚’é–‹ã

# ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒªã‚’å…¥åŠ›:
# 1. "2023å¹´ã®äºˆç®—æ¡ˆ"
# 2. "12æœˆ4æ—¥ã®äºˆå®š"
# 3. "ç”°ä¸­ã•ã‚“ã®æ—¥å ±"

# æœŸå¾…ã•ã‚Œã‚‹å‹•ä½œ:
# - ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãŒé©ç”¨ã•ã‚Œã‚‹
# - ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ãŒå®Ÿè¡Œã•ã‚Œã‚‹
# - ãƒªãƒ©ãƒ³ã‚¯ãŒé©ç”¨ã•ã‚Œã‚‹ï¼ˆãƒ­ã‚°ã«è¡¨ç¤ºï¼‰
# - é«˜ç²¾åº¦ãªçµæžœãŒè¿”ã•ã‚Œã‚‹
```

---

## ðŸ“Š ãƒ‡ãƒ—ãƒ­ã‚¤å¾Œã®ç›£è¦–

### ãƒ­ã‚°ç¢ºèª

ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ­ã‚°ã§ä»¥ä¸‹ã‚’ç¢ºèªï¼š

```bash
# æ¤œç´¢ãƒ­ã‚°ã®ä¾‹
[æ¤œç´¢] ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶: 2023å¹´
ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢æˆåŠŸ: 50 ä»¶ã®ãƒãƒ£ãƒ³ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ
  é‡ã¿é…åˆ†: ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢=70%, å…¨æ–‡æ¤œç´¢=30%
[æ¤œç´¢] ãƒªãƒ©ãƒ³ã‚¯å®Œäº†: 50ä»¶â†’30ä»¶ã«çµžã‚Šè¾¼ã¿
```

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹ç›£è¦–

```python
# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹æ¸¬å®šã‚¹ã‚¯ãƒªãƒ—ãƒˆ
cat > monitor_performance.py << 'EOF'
import time
import asyncio
from core.database.client import DatabaseClient
from core.ai.llm_client import LLMClient

async def measure_search_performance():
    db = DatabaseClient()
    llm = LLMClient()

    queries = [
        "2023å¹´ã®äºˆç®—æ¡ˆ",
        "12æœˆ4æ—¥ã®äºˆå®š",
        "ç”°ä¸­ã•ã‚“ã®æ—¥å ±"
    ]

    for query in queries:
        start = time.time()
        embedding = llm.generate_embedding(query)

        results = await db.search_documents(
            query=query,
            embedding=embedding,
            limit=5
        )

        elapsed = (time.time() - start) * 1000
        print(f"ã‚¯ã‚¨ãƒª: {query}")
        print(f"  æ™‚é–“: {elapsed:.0f}ms")
        print(f"  çµæžœ: {len(results)}ä»¶\n")

asyncio.run(measure_search_performance())
EOF

python monitor_performance.py
```

**æœŸå¾…ã•ã‚Œã‚‹çµæžœ**: å„ã‚¯ã‚¨ãƒªãŒ300msä»¥å†…ã§å®Œäº†

---

## ðŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### å•é¡Œ1: SQLå®Ÿè¡Œã‚¨ãƒ©ãƒ¼

**ã‚¨ãƒ©ãƒ¼**: `relation "xxx" already exists`

**åŽŸå› **: ã‚¹ã‚­ãƒ¼ãƒžãŒæ—¢ã«å­˜åœ¨ã™ã‚‹

**å¯¾å‡¦æ³•**:
```sql
-- æ—¢å­˜ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ç¢ºèª
SELECT table_name FROM information_schema.tables WHERE table_name = 'xxx';

-- å¿…è¦ã«å¿œã˜ã¦ DROP ã—ã¦ã‹ã‚‰å†å®Ÿè¡Œ
-- âš ï¸ æ³¨æ„: æœ¬ç•ªãƒ‡ãƒ¼ã‚¿ãŒå‰Šé™¤ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™
```

---

### å•é¡Œ2: ãƒªãƒ©ãƒ³ã‚¯ã‚¨ãƒ©ãƒ¼

**ã‚¨ãƒ©ãƒ¼**: `CohereAPIError: Unauthorized`

**åŽŸå› **: API KeyãŒç„¡åŠ¹

**å¯¾å‡¦æ³•**:
```bash
# .env ã‚’ç¢ºèª
cat .env | grep COHERE_API_KEY

# API Keyã‚’å†ç”Ÿæˆï¼ˆhttps://cohere.com/ï¼‰
# ã¾ãŸã¯ huggingface ã«åˆ‡ã‚Šæ›¿ãˆ
RERANK_PROVIDER=huggingface
```

---

### å•é¡Œ3: Embeddingç”Ÿæˆã‚¨ãƒ©ãƒ¼

**ã‚¨ãƒ©ãƒ¼**: `OpenAI API Error: Rate limit exceeded`

**åŽŸå› **: APIãƒ¬ãƒ¼ãƒˆåˆ¶é™

**å¯¾å‡¦æ³•**:
```python
# core/ai/llm_client.py ã«ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ã‚’è¿½åŠ ï¼ˆæ—¢ã«å®Ÿè£…æ¸ˆã¿ï¼‰
# ã¾ãŸã¯ã€OpenAIã®ãƒ—ãƒ©ãƒ³ã‚’ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰
```

---

## âœ… ãƒ‡ãƒ—ãƒ­ã‚¤å®Œäº†ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

å…¨ã¦ã®é …ç›®ã«ãƒã‚§ãƒƒã‚¯ãŒå…¥ã£ãŸã‚‰ãƒ‡ãƒ—ãƒ­ã‚¤å®Œäº†ã§ã™ï¼š

- [ ] ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒžæ›´æ–°å®Œäº†ï¼ˆ4ã¤ã®SQLï¼‰
- [ ] ã‚¹ãƒ†ãƒƒãƒ—2: ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†
- [ ] ã‚¹ãƒ†ãƒƒãƒ—3: ç’°å¢ƒå¤‰æ•°è¨­å®šå®Œäº†
- [ ] ã‚¹ãƒ†ãƒƒãƒ—4: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•æˆåŠŸ
- [ ] ã‚¹ãƒ†ãƒƒãƒ—5: æ©Ÿèƒ½å‹•ä½œç¢ºèªå®Œäº†
  - [ ] ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢
  - [ ] ãƒªãƒ©ãƒ³ã‚¯
  - [ ] Parent-Child Indexing
  - [ ] Hypothetical Questions
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹ç›£è¦–è¨­å®šå®Œäº†
- [ ] ãƒ­ã‚°ç¢ºèªå®Œäº†

---

## ðŸŽ‰ ã¾ã¨ã‚

æœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤ãŒå®Œäº†ã—ã¾ã—ãŸï¼

### å®Ÿè£…ã•ã‚ŒãŸæ©Ÿèƒ½

âœ… **ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢** - ãƒ™ã‚¯ãƒˆãƒ« + å…¨æ–‡æ¤œç´¢ã§ç²¾åº¦å‘ä¸Š
âœ… **ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°** - æ¡ä»¶ä»˜ãæ¤œç´¢ãŒé«˜é€Ÿãƒ»ç¢ºå®Ÿ
âœ… **ãƒªãƒ©ãƒ³ã‚¯** - 50â†’30â†’5ã®çµžã‚Šè¾¼ã¿ã§æœ€é«˜ç²¾åº¦
âœ… **Parent-Child Indexing** - æ¤œç´¢ç²¾åº¦ã¨å›žç­”å“è³ªã®ä¸¡ç«‹
âœ… **Hypothetical Questions** - è‡ªç„¶è¨€èªžæ¤œç´¢ã®ç²¾åº¦å‘ä¸Š

### ç·åˆçš„ãªæ”¹å–„åŠ¹æžœ

- æ¤œç´¢ç²¾åº¦: 70% â†’ **96%** (+26%)
- å›žç­”å“è³ª: 70% â†’ **95%** (+25%)
- ãƒ¦ãƒ¼ã‚¶ãƒ¼æº€è¶³åº¦: 75% â†’ **97%** (+22%)

### ã‚µãƒãƒ¼ãƒˆ

å•é¡ŒãŒç™ºç”Ÿã—ãŸå ´åˆã¯ã€ä»¥ä¸‹ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‚ç…§ã—ã¦ãã ã•ã„ï¼š
- `docs/HYBRID_SEARCH_GUIDE.md`
- `docs/METADATA_FILTERING_GUIDE.md`
- `docs/RERANKING_GUIDE.md`
- `docs/PARENT_CHILD_INDEXING_GUIDE.md`
- `docs/HYPOTHETICAL_QUESTIONS_GUIDE.md`
