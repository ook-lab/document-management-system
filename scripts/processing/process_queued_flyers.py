"""
ãƒãƒ©ã‚·å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

Rawdata_FLYER_shopsãƒ†ãƒ¼ãƒ–ãƒ«ã® processing_status='pending' ã®ãƒãƒ©ã‚·ã‚’å‡¦ç†

å‡¦ç†ãƒ•ãƒ­ãƒ¼:
1. Pre-processing: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
2. Stage B (Gemini Vision):
   - Step 1: OCR + ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè§£æ
   - Step 2: å•†å“æƒ…å ±ã®æ§‹é€ åŒ–æŠ½å‡º
3. Stage C (Gemini Flash): æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã®æœ€çµ‚æ•´ç†
4. Stage A (Gemini): è¦ç´„ç”Ÿæˆ
5. ãƒãƒ£ãƒ³ã‚¯åŒ–ãƒ»ãƒ™ã‚¯ãƒˆãƒ«åŒ–: search_indexã«ä¿å­˜

ä½¿ã„æ–¹:
    # å…¨ã¦ã®pendingãƒãƒ©ã‚·ã‚’å‡¦ç†ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ10ä»¶ï¼‰
    python process_queued_flyers.py

    # å‡¦ç†ä»¶æ•°ã‚’æŒ‡å®š
    python process_queued_flyers.py --limit=50

    # ç‰¹å®šã®åº—èˆ—ã®ã¿å‡¦ç†
    python process_queued_flyers.py --store="ãƒ•ãƒ¼ãƒ‡ã‚£ã‚¢ãƒ  æ­¦è”µå°æ‰"

    # ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ï¼ˆç¢ºèªã®ã¿ï¼‰
    python process_queued_flyers.py --dry-run
"""

import asyncio
import sys
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime
from loguru import logger
import hashlib

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
root_dir = Path(__file__).parent.parent.parent
sys.path.insert(0, str(root_dir))
sys.path.insert(0, str(root_dir / "services" / "data-ingestion"))

from shared.common.database.client import DatabaseClient
from shared.common.connectors.google_drive import GoogleDriveConnector
from shared.pipeline import UnifiedDocumentPipeline


class FlyerProcessor:
    """ãƒãƒ©ã‚·å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""

    def __init__(self, temp_dir: str = "./temp"):
        """
        Args:
            temp_dir: ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        self.db = DatabaseClient()
        self.drive = GoogleDriveConnector()

        # çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’åˆæœŸåŒ–
        self.pipeline = UnifiedDocumentPipeline(db_client=self.db)

        self.temp_dir = Path(temp_dir)
        self.temp_dir.mkdir(parents=True, exist_ok=True)

        logger.info("FlyerProcessoråˆæœŸåŒ–å®Œäº†ï¼ˆG_unified_pipelineä½¿ç”¨ï¼‰")

    def get_pending_flyers(
        self,
        limit: int = 10,
        store_name: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """
        å‡¦ç†å¾…ã¡ã®ãƒãƒ©ã‚·ã‚’å–å¾—

        Args:
            limit: å–å¾—ä»¶æ•°
            store_name: åº—èˆ—åï¼ˆæŒ‡å®šã•ã‚ŒãŸå ´åˆã®ã¿ï¼‰

        Returns:
            ãƒãƒ©ã‚·æƒ…å ±ã®ãƒªã‚¹ãƒˆ
        """
        try:
            query = self.db.client.table('Rawdata_FLYER_shops').select('*').eq(
                'processing_status', 'pending'
            )

            if store_name:
                query = query.eq('organization', store_name)

            result = query.limit(limit).execute()

            if result.data:
                logger.info(f"å‡¦ç†å¾…ã¡ãƒãƒ©ã‚·: {len(result.data)}ä»¶")
                return result.data

            return []

        except Exception as e:
            logger.error(f"ãƒãƒ©ã‚·å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []

    async def process_single_flyer(
        self,
        flyer_doc: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        1ä»¶ã®ãƒãƒ©ã‚·ã‚’å‡¦ç†ï¼ˆG_unified_pipelineä½¿ç”¨ï¼‰

        Args:
            flyer_doc: ãƒãƒ©ã‚·ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæƒ…å ±

        Returns:
            å‡¦ç†çµæœ
        """
        flyer_doc_id = flyer_doc['id']
        file_name = flyer_doc.get('file_name', 'ä¸æ˜')
        source_id = flyer_doc.get('source_id')  # Google Drive ID
        organization = flyer_doc.get('organization', 'ä¸æ˜')

        logger.info(f"\n{'='*80}")
        logger.info(f"ãƒãƒ©ã‚·å‡¦ç†é–‹å§‹: {file_name}")
        logger.info(f"  åº—èˆ—: {organization}")
        logger.info(f"  ID: {flyer_doc_id}")
        logger.info(f"{'='*80}")

        result = {
            'flyer_doc_id': flyer_doc_id,
            'file_name': file_name,
            'success': False,
            'products_count': 0,
            'chunks_count': 0,
            'error': None
        }

        local_path = None

        try:
            # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ 'processing' ã«æ›´æ–°
            self._update_status(flyer_doc_id, 'processing')

            # ============================================
            # Pre-processing: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            # ============================================
            logger.info("[Pre-processing] ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
            local_path = self.drive.download_file(source_id, file_name, self.temp_dir)

            if not local_path or not Path(local_path).exists():
                raise Exception("ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—")

            logger.info(f"  ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {local_path}")

            # ============================================
            # G_unified_pipeline ã§å‡¦ç†
            # ============================================
            logger.info("[G_unified_pipeline] ãƒãƒ©ã‚·å‡¦ç†é–‹å§‹...")

            # doc_type="flyer" ã§çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œ
            # â†’ config/prompts/stage_f/flyer.md
            # â†’ config/prompts/stage_g/flyer.md
            # â†’ config/prompts/stage_h/flyer.md
            # â†’ config/prompts/stage_i/flyer.md
            pipeline_result = await self.pipeline.process_document(
                file_path=Path(local_path),
                file_name=file_name,
                doc_type='flyer',  # â† ã“ã‚Œã§è‡ªå‹•çš„ã«ãƒãƒ©ã‚·ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ»ãƒ¢ãƒ‡ãƒ«ãŒé¸æŠã•ã‚Œã‚‹
                workspace='shopping',
                mime_type='image/jpeg',  # ãƒãƒ©ã‚·ã¯é€šå¸¸JPEG
                source_id=source_id,
                extra_metadata={
                    'organization': organization,
                    'flyer_title': flyer_doc.get('flyer_title'),
                    'flyer_period': flyer_doc.get('flyer_period'),
                    'page_number': flyer_doc.get('page_number'),
                    'flyer_doc_id': flyer_doc_id
                }
            )

            if not pipeline_result.get('success'):
                raise Exception(f"ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†å¤±æ•—: {pipeline_result.get('error')}")

            document_id = pipeline_result['document_id']
            chunks_count = pipeline_result.get('chunks_count', 0)

            logger.info(f"[G_unified_pipelineå®Œäº†] document_id={document_id}, chunks={chunks_count}")

            # ============================================
            # æˆåŠŸ
            # ============================================
            self._update_status(flyer_doc_id, 'completed')

            result.update({
                'success': True,
                'document_id': document_id,
                'chunks_count': chunks_count
            })

            logger.info(f"âœ… ãƒãƒ©ã‚·å‡¦ç†æˆåŠŸ: {file_name}")
            return result

        except Exception as e:
            error_msg = str(e)
            logger.error(f"âŒ ãƒãƒ©ã‚·å‡¦ç†ã‚¨ãƒ©ãƒ¼: {error_msg}", exc_info=True)

            self._update_status(flyer_doc_id, 'error', error_message=error_msg)

            result['error'] = error_msg
            return result

        finally:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            if local_path and Path(local_path).exists():
                try:
                    Path(local_path).unlink()
                    logger.debug(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤: {local_path}")
                except Exception as e:
                    logger.warning(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤å¤±æ•—: {e}")

    async def _save_products(
        self,
        flyer_doc_id: str,
        products: List[Dict[str, Any]],
        page_number: int
    ) -> int:
        """
        å•†å“æƒ…å ±ã‚’Rawdata_FLYER_itemsãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜

        Args:
            flyer_doc_id: ãƒãƒ©ã‚·ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆID
            products: å•†å“ãƒªã‚¹ãƒˆ
            page_number: ãƒšãƒ¼ã‚¸ç•ªå·

        Returns:
            ä¿å­˜æˆåŠŸä»¶æ•°
        """
        success_count = 0

        for product in products:
            try:
                # å•†å“åã®æ­£è¦åŒ–ï¼ˆæ¤œç´¢ç”¨ï¼‰
                product_name = product.get('product_name', '')
                product_name_normalized = product_name.lower().strip()

                product_data = {
                    'flyer_document_id': flyer_doc_id,
                    'product_name': product_name,
                    'product_name_normalized': product_name_normalized,
                    'price': product.get('price'),
                    'original_price': product.get('original_price'),
                    'discount_rate': product.get('discount_rate'),
                    'price_unit': product.get('price_unit', 'å††'),
                    'price_text': product.get('price_text'),
                    'category': product.get('category', 'ãã®ä»–'),
                    'subcategory': product.get('subcategory'),
                    'brand': product.get('brand'),
                    'quantity': product.get('quantity'),
                    'origin': product.get('origin'),
                    'is_special_offer': product.get('is_special_offer', False),
                    'offer_type': product.get('offer_type'),
                    'page_number': page_number,
                    'extracted_text': product.get('extracted_text'),
                    'confidence': product.get('confidence', 0.5),
                    'metadata': {
                        'extraction_date': datetime.now().isoformat(),
                        'extraction_model': 'gemini-2.0-flash-exp'
                    }
                }

                result = await self.db.insert_document('Rawdata_FLYER_items', product_data)
                if result:
                    success_count += 1

            except Exception as e:
                logger.error(f"å•†å“ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
                logger.debug(f"å•†å“ãƒ‡ãƒ¼ã‚¿: {product}")

        return success_count

    def _update_status(
        self,
        flyer_doc_id: str,
        status: str,
        error: str = None
    ):
        """
        ãƒãƒ©ã‚·ã®å‡¦ç†ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’æ›´æ–°

        Args:
            flyer_doc_id: ãƒãƒ©ã‚·ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆID
            status: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ï¼ˆprocessing, completed, failedï¼‰
            error: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        """
        try:
            update_data = {
                'processing_status': status,
                'updated_at': datetime.now().isoformat()
            }

            if error:
                update_data['processing_error'] = error

            self.db.client.table('Rawdata_FLYER_shops').update(update_data).eq(
                'id', flyer_doc_id
            ).execute()

        except Exception as e:
            logger.error(f"ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")

    async def process_pending_flyers(
        self,
        limit: int = 10,
        store_name: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        å‡¦ç†å¾…ã¡ã®ãƒãƒ©ã‚·ã‚’ä¸€æ‹¬å‡¦ç†

        Args:
            limit: å‡¦ç†ä»¶æ•°
            store_name: åº—èˆ—åï¼ˆæŒ‡å®šã•ã‚ŒãŸå ´åˆã®ã¿ï¼‰

        Returns:
            å‡¦ç†çµæœã®ã‚µãƒãƒªãƒ¼
        """
        logger.info("=" * 80)
        logger.info("ãƒãƒ©ã‚·å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é–‹å§‹")
        logger.info("=" * 80)

        # å‡¦ç†å¾…ã¡ãƒãƒ©ã‚·ã‚’å–å¾—
        pending_flyers = self.get_pending_flyers(limit, store_name)

        if not pending_flyers:
            logger.info("å‡¦ç†å¾…ã¡ã®ãƒãƒ©ã‚·ã¯ã‚ã‚Šã¾ã›ã‚“")
            return {'total': 0, 'success': 0, 'failed': 0, 'total_products': 0, 'total_chunks': 0}

        logger.info(f"å‡¦ç†å¯¾è±¡: {len(pending_flyers)}ä»¶")

        results = []
        for i, flyer in enumerate(pending_flyers, 1):
            logger.info(f"\n[{i}/{len(pending_flyers)}] å‡¦ç†ä¸­...")
            result = await self.process_single_flyer(flyer)
            results.append(result)

        # ã‚µãƒãƒªãƒ¼
        success_count = sum(1 for r in results if r['success'])
        failed_count = len(results) - success_count
        total_products = sum(r.get('products_count', 0) for r in results)
        total_chunks = sum(r.get('chunks_count', 0) for r in results)

        logger.info("\n" + "=" * 80)
        logger.info("å‡¦ç†å®Œäº†")
        logger.info(f"  æˆåŠŸ: {success_count}/{len(results)}")
        logger.info(f"  å¤±æ•—: {failed_count}/{len(results)}")
        logger.info(f"  æŠ½å‡ºå•†å“æ•°: {total_products}ä»¶")
        logger.info(f"  ç”Ÿæˆãƒãƒ£ãƒ³ã‚¯æ•°: {total_chunks}å€‹")
        logger.info("=" * 80)

        return {
            'total': len(results),
            'success': success_count,
            'failed': failed_count,
            'total_products': total_products,
            'total_chunks': total_chunks,
            'results': results
        }


async def main():
    """ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®ãƒ‘ãƒ¼ã‚¹
    dry_run = '--dry-run' in sys.argv
    limit = 10
    store_name = None

    for arg in sys.argv:
        if arg.startswith('--limit='):
            try:
                limit = int(arg.split('=')[1])
            except:
                pass
        elif arg.startswith('--store='):
            store_name = arg.split('=')[1]

    processor = FlyerProcessor()

    if dry_run:
        logger.info("ğŸ” DRY RUN ãƒ¢ãƒ¼ãƒ‰: å®Ÿéš›ã®å‡¦ç†ã¯è¡Œã„ã¾ã›ã‚“")
        pending = processor.get_pending_flyers(limit, store_name)
        logger.info(f"å‡¦ç†å¯¾è±¡: {len(pending)}ä»¶")
        for flyer in pending:
            logger.info(f"  - {flyer.get('organization')}: {flyer.get('file_name')}")
        return

    result = await processor.process_pending_flyers(limit, store_name)

    # çµæœã‚’è¡¨ç¤º
    print("\n" + "=" * 80)
    print("ğŸ›’ ãƒãƒ©ã‚·å‡¦ç†çµæœ")
    print("=" * 80)
    print(f"å‡¦ç†ä»¶æ•°: {result['total']}")
    print(f"æˆåŠŸ: {result['success']}")
    print(f"å¤±æ•—: {result['failed']}")
    print(f"æŠ½å‡ºå•†å“æ•°: {result['total_products']}")
    print(f"ç”Ÿæˆãƒãƒ£ãƒ³ã‚¯æ•°: {result['total_chunks']}")
    print("=" * 80)


if __name__ == "__main__":
    asyncio.run(main())
