"""
å…¨ãƒ‡ãƒ¼ã‚¿å†å–ã‚Šè¾¼ã¿ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰PDFæŠ½å‡ºï¼ˆpypdf + Gemini Visionï¼‰ã§å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†å‡¦ç†
"""
import os
import asyncio
from datetime import datetime
from dotenv import load_dotenv
from loguru import logger

from pipelines.two_stage_ingestion import TwoStageIngestionPipeline
from core.database.client import DatabaseClient

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()

# çµ±è¨ˆæƒ…å ±
class ProcessingStats:
    def __init__(self):
        self.total = 0
        self.success = 0
        self.skipped = 0
        self.failed = 0
        self.vision_used = 0
        self.errors = []
        self.start_time = None
        self.end_time = None

    def add_success(self, file_name, vision_used=False):
        self.success += 1
        if vision_used:
            self.vision_used += 1
        logger.info(f"âœ… [{self.success}/{self.total}] æˆåŠŸ: {file_name}")

    def add_skipped(self, file_name):
        self.skipped += 1
        logger.info(f"â­ï¸  [{self.success + self.skipped + self.failed}/{self.total}] ã‚¹ã‚­ãƒƒãƒ—: {file_name}")

    def add_failed(self, file_name, error):
        self.failed += 1
        error_msg = str(error)
        self.errors.append((file_name, error_msg))
        logger.error(f"âŒ [{self.success + self.skipped + self.failed}/{self.total}] å¤±æ•—: {file_name} - {error_msg}")

    def print_summary(self):
        """å‡¦ç†çµæœã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
        duration = (self.end_time - self.start_time).total_seconds() if self.end_time and self.start_time else 0

        logger.info("=" * 80)
        logger.info("ğŸ“Š å…¨ãƒ‡ãƒ¼ã‚¿å†å–ã‚Šè¾¼ã¿å®Œäº†")
        logger.info("=" * 80)
        logger.info(f"ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°:     {self.total} ä»¶")
        logger.info(f"âœ… æˆåŠŸ:          {self.success} ä»¶")
        logger.info(f"â­ï¸  ã‚¹ã‚­ãƒƒãƒ—:      {self.skipped} ä»¶")
        logger.info(f"âŒ å¤±æ•—:          {self.failed} ä»¶")
        logger.info(f"ğŸ¤– Visionè£œå®Œ:    {self.vision_used} ä»¶")
        logger.info(f"â±ï¸  å‡¦ç†æ™‚é–“:      {duration:.1f} ç§’ ({duration/60:.1f} åˆ†)")

        if self.errors:
            logger.warning("-" * 80)
            logger.warning(f"âŒ ã‚¨ãƒ©ãƒ¼è©³ç´° ({len(self.errors)} ä»¶):")
            for file_name, error_msg in self.errors:
                logger.warning(f"   - {file_name}: {error_msg}")

        logger.info("=" * 80)


async def reingest_all_data(skip_existing: bool = True):
    """
    å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å†å–ã‚Šè¾¼ã¿

    Args:
        skip_existing: æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã‹ï¼ˆTrue: ã‚¹ã‚­ãƒƒãƒ—ã€False: å‰Šé™¤ã—ã¦å†å‡¦ç†ï¼‰
    """
    stats = ProcessingStats()
    stats.start_time = datetime.now()

    logger.info("=" * 80)
    logger.info("ğŸš€ å…¨ãƒ‡ãƒ¼ã‚¿å†å–ã‚Šè¾¼ã¿é–‹å§‹")
    logger.info("=" * 80)
    logger.info(f"ã‚¹ã‚­ãƒƒãƒ—ãƒ¢ãƒ¼ãƒ‰: {'ON (æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã¯ã‚¹ã‚­ãƒƒãƒ—)' if skip_existing else 'OFF (æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¦å†å‡¦ç†)'}")
    logger.info("-" * 80)

    # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–
    try:
        pipeline = TwoStageIngestionPipeline()
        logger.info("âœ… ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–å®Œäº†")
    except Exception as e:
        logger.critical(f"âŒ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–å¤±æ•—: {e}")
        return

    # Google Drive ãƒ•ã‚©ãƒ«ãƒ€IDå–å¾—
    folder_id = os.getenv('PERSONAL_FOLDER_ID')
    if not folder_id:
        logger.critical("âŒ PERSONAL_FOLDER_ID ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return

    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆå–å¾—
    try:
        files = pipeline.drive.list_files_in_folder(folder_id)
        stats.total = len(files)
        logger.info(f"ğŸ“ å–å¾—ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {stats.total} ä»¶")
        logger.info("-" * 80)
    except Exception as e:
        logger.critical(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆå–å¾—å¤±æ•—: {e}")
        return

    # PDFãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ãƒ•ã‚£ãƒ«ã‚¿
    pdf_files = [f for f in files if f.get('mimeType') == 'application/pdf']
    stats.total = len(pdf_files)
    logger.info(f"ğŸ“„ PDFãƒ•ã‚¡ã‚¤ãƒ«æ•°: {stats.total} ä»¶")
    logger.info("-" * 80)

    # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†
    if not skip_existing:
        logger.warning("âš ï¸  æ—¢å­˜ãƒ‡ãƒ¼ã‚¿å‰Šé™¤ãƒ¢ãƒ¼ãƒ‰: ã™ã¹ã¦ã®æ—¢å­˜PDFãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¾ã™")
        try:
            db = DatabaseClient()
            # ã™ã¹ã¦ã®PDFãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‰Šé™¤
            response = db.client.table('documents').select('id, file_name').eq('file_type', 'pdf').execute()
            if response.data:
                for doc in response.data:
                    db.client.table('documents').delete().eq('id', doc['id']).execute()
                logger.info(f"ğŸ—‘ï¸  å‰Šé™¤å®Œäº†: {len(response.data)} ä»¶")
        except Exception as e:
            logger.error(f"âŒ æ—¢å­˜ãƒ‡ãƒ¼ã‚¿å‰Šé™¤å¤±æ•—: {e}")
            logger.warning("âš ï¸  å‡¦ç†ã‚’ç¶™ç¶šã—ã¾ã™ãŒã€é‡è¤‡ãƒ‡ãƒ¼ã‚¿ãŒç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")

    # å„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
    for idx, file_meta in enumerate(pdf_files, 1):
        file_name = file_meta.get('name', 'Unknown')

        logger.info(f"\n[{idx}/{stats.total}] å‡¦ç†é–‹å§‹: {file_name}")

        try:
            result = await pipeline.process_file(file_meta, workspace='family')

            if result is None:
                # ã‚¹ã‚­ãƒƒãƒ—ï¼ˆæ—¢å­˜ãƒ‡ãƒ¼ã‚¿ç­‰ï¼‰
                stats.add_skipped(file_name)
            else:
                # æˆåŠŸ
                vision_used = result.get('metadata', {}).get('vision_supplemented', False)
                stats.add_success(file_name, vision_used=vision_used)

                # Visionè£œå®Œã®è©³ç´°ãƒ­ã‚°
                if vision_used:
                    vision_pages = result.get('metadata', {}).get('vision_pages', 0)
                    logger.info(f"   ğŸ¤– Visionè£œå®Œ: {vision_pages} ãƒšãƒ¼ã‚¸")

        except Exception as e:
            # å¤±æ•—ã—ã¦ã‚‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ç¶™ç¶š
            stats.add_failed(file_name, e)
            import traceback
            logger.error(traceback.format_exc())
            continue

    # å‡¦ç†å®Œäº†
    stats.end_time = datetime.now()
    stats.print_summary()


if __name__ == "__main__":
    # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦å‡¦ç†ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
    # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¦å†å‡¦ç†ã™ã‚‹å ´åˆã¯ skip_existing=False ã«å¤‰æ›´
    asyncio.run(reingest_all_data(skip_existing=True))
